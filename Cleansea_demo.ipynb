{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGmEJ5s9OvDb"
      },
      "source": [
        "# The CleanSea Set: A Benchmark Corpus for Underwater Debris Detection and Recognition\n",
        "\n",
        " Realizado por: [Alejandro Sanchez Ferrer](mailto:alejandro_sanchez_ferrer@hotmail.com), [Antonio Javier Gallego](mailto:jgallego@dlsi.ua.es), Jorge Calvo Zaragoza & Jose Javier Valero Mas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-Sn7zuMN872"
      },
      "source": [
        "## **Import dependencies y Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qL51SxCt_djw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import glob\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import preprocessing\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJHD0oDE5mul"
      },
      "source": [
        "## **Dataset Definition**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbuiIIHlLih6"
      },
      "source": [
        "### Label and Image Storage\n",
        "Once we have our data set and imported the main libraries, we proceed to prepare the data for the Mask RCNN. First, we will order the dataset according to the label that each image has. To do this we will read each **JSON** file and see that **\"Label\"** has that image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AzoYVLtLxSU",
        "outputId": "e298d0a2-f338-46c2-be08-d5e6af083fac"
      },
      "outputs": [],
      "source": [
        "# Configuration of the path for the images\n",
        "IMG_PATH = \"../synthetic_dataset/images\"\n",
        "\n",
        "# Configure the path for the .json files\n",
        "JSON_PATH = \"../synthetic_dataset/labels\"\n",
        "\n",
        "# We read all the json and extract the toppic 'labels' to store it in a variable with all the labels of all the images.\n",
        "nlabels=[]\n",
        "img_names= []\n",
        "\n",
        "# We go through the folder where the .json are stored\n",
        "for file_name in [file for file in os.listdir(JSON_PATH)]:\n",
        "  with open(os.path.join(JSON_PATH,file_name),'r', encoding='utf8') as json_file:\n",
        "    content= json.load(json_file)\n",
        "    # Store with which image it is related\n",
        "    jpegname= content['imagePath']\n",
        "    # Store the number of polygons that are inside said .json\n",
        "    nshapes= len(content['shapes'])\n",
        "    # We collect the labels of each of the previous polygons\n",
        "    for topic in range(nshapes):\n",
        "      label=content['shapes'][topic]['label']\n",
        "      # Add each label to the list of labels (except the classes with the Metal_Chain and WashingMachine labels since they do not have the minimum samples to be able to separate them) and the path of all the images\n",
        "      if label != 'Metal_Chain' and label != 'WashingMachine':\n",
        "        img_names.append( os.path.join(IMG_PATH, content['imagePath']))\n",
        "        nlabels.append(label)\n",
        "\n",
        "labels=np.array(nlabels)\n",
        "img_names=np.array(img_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izJvdGzXPXde"
      },
      "source": [
        "## **Label Encoding**\n",
        "Una vez tenemos el label de cada imagen y almacenado en un array, con *ecdr.classes_* obtendremos todos los labels de todas las imagenes cargadas.\n",
        "\n",
        "Para ello utilizaremos el metodo *LabelEnconder* de la libreria *sklearn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wgg70TKIrKRn",
        "outputId": "2f60e389-a796-475d-8cf7-a4632df74032"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basket : 60\n",
            "Bottle : 228\n",
            "Can : 598\n",
            "Car_Bumper : 95\n",
            "Fishing_Net : 186\n",
            "Glove : 57\n",
            "Metal_Debris : 33\n",
            "Packaging_Bag : 346\n",
            "Pipe : 67\n",
            "Plastic_Bag : 977\n",
            "Plastic_Debris : 146\n",
            "Rope : 113\n",
            "Shoe : 12\n",
            "Squared_Can : 23\n",
            "Tire : 25\n",
            "Towel : 73\n",
            "Wood : 96\n"
          ]
        }
      ],
      "source": [
        "#Obtenemos todas las labels unicos existentes en nuestro dataset\n",
        "labels, count = np.unique(nlabels, return_counts=True)\n",
        "#Los mostramos\n",
        "for idx, l in enumerate(labels):\n",
        "  print(l, ':', count[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3B9dr6HlEMa"
      },
      "source": [
        "Transform the labels to a **normalized encoding (Numeric)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx0vskL5kkDy",
        "outputId": "51b67185-c434-4061-ce8d-49625929f748"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2 8 2 ... 9 9 9]\n"
          ]
        }
      ],
      "source": [
        "# Initialize the label encoder\n",
        "le = preprocessing.LabelEncoder()\n",
        "# Fit the labels in the encoder\n",
        "le.fit(nlabels)\n",
        "# Apply the encoding to the entered labels and store them\n",
        "Y = le.transform(nlabels)\n",
        "\n",
        "# Show the encoded labels\n",
        "print(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyYIxexetudA"
      },
      "source": [
        "## **Dataset Split: Train & Test**\n",
        "Once we have both the images and the labels we can use the *[StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html)* method to generate the data sets of Test and Training that contain the same distribution of labels or as close as possible\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXjcfKdLuj8-",
        "outputId": "57628974-31a7-43ad-9211-e0f540192f64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Images to be moved to Train Folder: \n",
            " ['../synthetic_dataset/images\\\\image_17.jpg'\n",
            " '../synthetic_dataset/images\\\\image_187.jpg'\n",
            " '../synthetic_dataset/images\\\\image_195.jpg' ...\n",
            " '../synthetic_dataset/images\\\\image_99.jpg'\n",
            " '../synthetic_dataset/images\\\\image_99.jpg'\n",
            " '../synthetic_dataset/images\\\\image_99.jpg']\n",
            "\n",
            " Images to be moved to Test Folder: \n",
            " ['../synthetic_dataset/images\\\\image_0.jpg'\n",
            " '../synthetic_dataset/images\\\\image_0.jpg'\n",
            " '../synthetic_dataset/images\\\\image_0.jpg'\n",
            " '../synthetic_dataset/images\\\\image_1.jpg'\n",
            " '../synthetic_dataset/images\\\\image_1.jpg'\n",
            " '../synthetic_dataset/images\\\\image_1.jpg'\n",
            " '../synthetic_dataset/images\\\\image_1.jpg'\n",
            " '../synthetic_dataset/images\\\\image_1.jpg'\n",
            " '../synthetic_dataset/images\\\\image_1.jpg'\n",
            " '../synthetic_dataset/images\\\\image_1.jpg'\n",
            " '../synthetic_dataset/images\\\\image_1.jpg'\n",
            " '../synthetic_dataset/images\\\\image_10.jpg'\n",
            " '../synthetic_dataset/images\\\\image_100.jpg'\n",
            " '../synthetic_dataset/images\\\\image_100.jpg'\n",
            " '../synthetic_dataset/images\\\\image_100.jpg'\n",
            " '../synthetic_dataset/images\\\\image_100.jpg'\n",
            " '../synthetic_dataset/images\\\\image_101.jpg'\n",
            " '../synthetic_dataset/images\\\\image_101.jpg'\n",
            " '../synthetic_dataset/images\\\\image_101.jpg'\n",
            " '../synthetic_dataset/images\\\\image_101.jpg'\n",
            " '../synthetic_dataset/images\\\\image_101.jpg'\n",
            " '../synthetic_dataset/images\\\\image_102.jpg'\n",
            " '../synthetic_dataset/images\\\\image_102.jpg'\n",
            " '../synthetic_dataset/images\\\\image_102.jpg'\n",
            " '../synthetic_dataset/images\\\\image_102.jpg'\n",
            " '../synthetic_dataset/images\\\\image_102.jpg'\n",
            " '../synthetic_dataset/images\\\\image_102.jpg'\n",
            " '../synthetic_dataset/images\\\\image_102.jpg'\n",
            " '../synthetic_dataset/images\\\\image_103.jpg'\n",
            " '../synthetic_dataset/images\\\\image_103.jpg'\n",
            " '../synthetic_dataset/images\\\\image_103.jpg'\n",
            " '../synthetic_dataset/images\\\\image_103.jpg'\n",
            " '../synthetic_dataset/images\\\\image_103.jpg'\n",
            " '../synthetic_dataset/images\\\\image_103.jpg'\n",
            " '../synthetic_dataset/images\\\\image_104.jpg'\n",
            " '../synthetic_dataset/images\\\\image_104.jpg'\n",
            " '../synthetic_dataset/images\\\\image_104.jpg'\n",
            " '../synthetic_dataset/images\\\\image_104.jpg'\n",
            " '../synthetic_dataset/images\\\\image_104.jpg'\n",
            " '../synthetic_dataset/images\\\\image_105.jpg'\n",
            " '../synthetic_dataset/images\\\\image_105.jpg'\n",
            " '../synthetic_dataset/images\\\\image_106.jpg'\n",
            " '../synthetic_dataset/images\\\\image_106.jpg'\n",
            " '../synthetic_dataset/images\\\\image_106.jpg'\n",
            " '../synthetic_dataset/images\\\\image_106.jpg'\n",
            " '../synthetic_dataset/images\\\\image_106.jpg'\n",
            " '../synthetic_dataset/images\\\\image_106.jpg'\n",
            " '../synthetic_dataset/images\\\\image_106.jpg'\n",
            " '../synthetic_dataset/images\\\\image_107.jpg'\n",
            " '../synthetic_dataset/images\\\\image_107.jpg'\n",
            " '../synthetic_dataset/images\\\\image_107.jpg'\n",
            " '../synthetic_dataset/images\\\\image_108.jpg'\n",
            " '../synthetic_dataset/images\\\\image_108.jpg'\n",
            " '../synthetic_dataset/images\\\\image_108.jpg'\n",
            " '../synthetic_dataset/images\\\\image_108.jpg'\n",
            " '../synthetic_dataset/images\\\\image_108.jpg'\n",
            " '../synthetic_dataset/images\\\\image_109.jpg'\n",
            " '../synthetic_dataset/images\\\\image_109.jpg'\n",
            " '../synthetic_dataset/images\\\\image_109.jpg'\n",
            " '../synthetic_dataset/images\\\\image_109.jpg'\n",
            " '../synthetic_dataset/images\\\\image_11.jpg'\n",
            " '../synthetic_dataset/images\\\\image_110.jpg'\n",
            " '../synthetic_dataset/images\\\\image_110.jpg'\n",
            " '../synthetic_dataset/images\\\\image_110.jpg'\n",
            " '../synthetic_dataset/images\\\\image_110.jpg'\n",
            " '../synthetic_dataset/images\\\\image_111.jpg'\n",
            " '../synthetic_dataset/images\\\\image_111.jpg'\n",
            " '../synthetic_dataset/images\\\\image_111.jpg'\n",
            " '../synthetic_dataset/images\\\\image_111.jpg'\n",
            " '../synthetic_dataset/images\\\\image_112.jpg'\n",
            " '../synthetic_dataset/images\\\\image_112.jpg'\n",
            " '../synthetic_dataset/images\\\\image_113.jpg'\n",
            " '../synthetic_dataset/images\\\\image_114.jpg'\n",
            " '../synthetic_dataset/images\\\\image_115.jpg'\n",
            " '../synthetic_dataset/images\\\\image_115.jpg'\n",
            " '../synthetic_dataset/images\\\\image_115.jpg'\n",
            " '../synthetic_dataset/images\\\\image_115.jpg'\n",
            " '../synthetic_dataset/images\\\\image_115.jpg'\n",
            " '../synthetic_dataset/images\\\\image_115.jpg'\n",
            " '../synthetic_dataset/images\\\\image_116.jpg'\n",
            " '../synthetic_dataset/images\\\\image_117.jpg'\n",
            " '../synthetic_dataset/images\\\\image_117.jpg'\n",
            " '../synthetic_dataset/images\\\\image_117.jpg'\n",
            " '../synthetic_dataset/images\\\\image_117.jpg'\n",
            " '../synthetic_dataset/images\\\\image_117.jpg'\n",
            " '../synthetic_dataset/images\\\\image_117.jpg'\n",
            " '../synthetic_dataset/images\\\\image_117.jpg'\n",
            " '../synthetic_dataset/images\\\\image_118.jpg'\n",
            " '../synthetic_dataset/images\\\\image_118.jpg'\n",
            " '../synthetic_dataset/images\\\\image_118.jpg'\n",
            " '../synthetic_dataset/images\\\\image_118.jpg'\n",
            " '../synthetic_dataset/images\\\\image_118.jpg'\n",
            " '../synthetic_dataset/images\\\\image_119.jpg'\n",
            " '../synthetic_dataset/images\\\\image_119.jpg'\n",
            " '../synthetic_dataset/images\\\\image_119.jpg'\n",
            " '../synthetic_dataset/images\\\\image_119.jpg'\n",
            " '../synthetic_dataset/images\\\\image_12.jpg'\n",
            " '../synthetic_dataset/images\\\\image_12.jpg'\n",
            " '../synthetic_dataset/images\\\\image_12.jpg'\n",
            " '../synthetic_dataset/images\\\\image_12.jpg'\n",
            " '../synthetic_dataset/images\\\\image_12.jpg'\n",
            " '../synthetic_dataset/images\\\\image_12.jpg'\n",
            " '../synthetic_dataset/images\\\\image_12.jpg'\n",
            " '../synthetic_dataset/images\\\\image_120.jpg'\n",
            " '../synthetic_dataset/images\\\\image_120.jpg'\n",
            " '../synthetic_dataset/images\\\\image_120.jpg'\n",
            " '../synthetic_dataset/images\\\\image_120.jpg'\n",
            " '../synthetic_dataset/images\\\\image_120.jpg'\n",
            " '../synthetic_dataset/images\\\\image_120.jpg'\n",
            " '../synthetic_dataset/images\\\\image_121.jpg'\n",
            " '../synthetic_dataset/images\\\\image_121.jpg'\n",
            " '../synthetic_dataset/images\\\\image_121.jpg'\n",
            " '../synthetic_dataset/images\\\\image_121.jpg'\n",
            " '../synthetic_dataset/images\\\\image_122.jpg'\n",
            " '../synthetic_dataset/images\\\\image_122.jpg'\n",
            " '../synthetic_dataset/images\\\\image_122.jpg'\n",
            " '../synthetic_dataset/images\\\\image_122.jpg'\n",
            " '../synthetic_dataset/images\\\\image_122.jpg'\n",
            " '../synthetic_dataset/images\\\\image_122.jpg'\n",
            " '../synthetic_dataset/images\\\\image_122.jpg'\n",
            " '../synthetic_dataset/images\\\\image_123.jpg'\n",
            " '../synthetic_dataset/images\\\\image_124.jpg'\n",
            " '../synthetic_dataset/images\\\\image_124.jpg'\n",
            " '../synthetic_dataset/images\\\\image_125.jpg'\n",
            " '../synthetic_dataset/images\\\\image_125.jpg'\n",
            " '../synthetic_dataset/images\\\\image_125.jpg'\n",
            " '../synthetic_dataset/images\\\\image_126.jpg'\n",
            " '../synthetic_dataset/images\\\\image_126.jpg'\n",
            " '../synthetic_dataset/images\\\\image_126.jpg'\n",
            " '../synthetic_dataset/images\\\\image_126.jpg'\n",
            " '../synthetic_dataset/images\\\\image_126.jpg'\n",
            " '../synthetic_dataset/images\\\\image_126.jpg'\n",
            " '../synthetic_dataset/images\\\\image_126.jpg'\n",
            " '../synthetic_dataset/images\\\\image_126.jpg'\n",
            " '../synthetic_dataset/images\\\\image_126.jpg'\n",
            " '../synthetic_dataset/images\\\\image_127.jpg'\n",
            " '../synthetic_dataset/images\\\\image_127.jpg'\n",
            " '../synthetic_dataset/images\\\\image_127.jpg'\n",
            " '../synthetic_dataset/images\\\\image_128.jpg'\n",
            " '../synthetic_dataset/images\\\\image_128.jpg'\n",
            " '../synthetic_dataset/images\\\\image_128.jpg'\n",
            " '../synthetic_dataset/images\\\\image_128.jpg'\n",
            " '../synthetic_dataset/images\\\\image_128.jpg'\n",
            " '../synthetic_dataset/images\\\\image_128.jpg'\n",
            " '../synthetic_dataset/images\\\\image_128.jpg'\n",
            " '../synthetic_dataset/images\\\\image_128.jpg'\n",
            " '../synthetic_dataset/images\\\\image_129.jpg'\n",
            " '../synthetic_dataset/images\\\\image_129.jpg'\n",
            " '../synthetic_dataset/images\\\\image_129.jpg'\n",
            " '../synthetic_dataset/images\\\\image_129.jpg'\n",
            " '../synthetic_dataset/images\\\\image_129.jpg'\n",
            " '../synthetic_dataset/images\\\\image_13.jpg'\n",
            " '../synthetic_dataset/images\\\\image_13.jpg'\n",
            " '../synthetic_dataset/images\\\\image_13.jpg'\n",
            " '../synthetic_dataset/images\\\\image_13.jpg'\n",
            " '../synthetic_dataset/images\\\\image_13.jpg'\n",
            " '../synthetic_dataset/images\\\\image_13.jpg'\n",
            " '../synthetic_dataset/images\\\\image_13.jpg'\n",
            " '../synthetic_dataset/images\\\\image_13.jpg'\n",
            " '../synthetic_dataset/images\\\\image_13.jpg'\n",
            " '../synthetic_dataset/images\\\\image_130.jpg'\n",
            " '../synthetic_dataset/images\\\\image_130.jpg'\n",
            " '../synthetic_dataset/images\\\\image_130.jpg'\n",
            " '../synthetic_dataset/images\\\\image_130.jpg'\n",
            " '../synthetic_dataset/images\\\\image_130.jpg'\n",
            " '../synthetic_dataset/images\\\\image_131.jpg'\n",
            " '../synthetic_dataset/images\\\\image_131.jpg'\n",
            " '../synthetic_dataset/images\\\\image_131.jpg'\n",
            " '../synthetic_dataset/images\\\\image_131.jpg'\n",
            " '../synthetic_dataset/images\\\\image_131.jpg'\n",
            " '../synthetic_dataset/images\\\\image_131.jpg'\n",
            " '../synthetic_dataset/images\\\\image_132.jpg'\n",
            " '../synthetic_dataset/images\\\\image_132.jpg'\n",
            " '../synthetic_dataset/images\\\\image_132.jpg'\n",
            " '../synthetic_dataset/images\\\\image_132.jpg'\n",
            " '../synthetic_dataset/images\\\\image_132.jpg'\n",
            " '../synthetic_dataset/images\\\\image_133.jpg'\n",
            " '../synthetic_dataset/images\\\\image_133.jpg'\n",
            " '../synthetic_dataset/images\\\\image_134.jpg'\n",
            " '../synthetic_dataset/images\\\\image_134.jpg'\n",
            " '../synthetic_dataset/images\\\\image_134.jpg'\n",
            " '../synthetic_dataset/images\\\\image_135.jpg'\n",
            " '../synthetic_dataset/images\\\\image_135.jpg'\n",
            " '../synthetic_dataset/images\\\\image_135.jpg'\n",
            " '../synthetic_dataset/images\\\\image_135.jpg'\n",
            " '../synthetic_dataset/images\\\\image_135.jpg'\n",
            " '../synthetic_dataset/images\\\\image_135.jpg'\n",
            " '../synthetic_dataset/images\\\\image_135.jpg'\n",
            " '../synthetic_dataset/images\\\\image_136.jpg'\n",
            " '../synthetic_dataset/images\\\\image_136.jpg'\n",
            " '../synthetic_dataset/images\\\\image_136.jpg'\n",
            " '../synthetic_dataset/images\\\\image_136.jpg'\n",
            " '../synthetic_dataset/images\\\\image_136.jpg'\n",
            " '../synthetic_dataset/images\\\\image_136.jpg'\n",
            " '../synthetic_dataset/images\\\\image_136.jpg'\n",
            " '../synthetic_dataset/images\\\\image_137.jpg'\n",
            " '../synthetic_dataset/images\\\\image_137.jpg'\n",
            " '../synthetic_dataset/images\\\\image_137.jpg'\n",
            " '../synthetic_dataset/images\\\\image_137.jpg'\n",
            " '../synthetic_dataset/images\\\\image_137.jpg'\n",
            " '../synthetic_dataset/images\\\\image_137.jpg'\n",
            " '../synthetic_dataset/images\\\\image_137.jpg'\n",
            " '../synthetic_dataset/images\\\\image_137.jpg'\n",
            " '../synthetic_dataset/images\\\\image_138.jpg'\n",
            " '../synthetic_dataset/images\\\\image_138.jpg'\n",
            " '../synthetic_dataset/images\\\\image_138.jpg'\n",
            " '../synthetic_dataset/images\\\\image_138.jpg'\n",
            " '../synthetic_dataset/images\\\\image_139.jpg'\n",
            " '../synthetic_dataset/images\\\\image_139.jpg'\n",
            " '../synthetic_dataset/images\\\\image_139.jpg'\n",
            " '../synthetic_dataset/images\\\\image_139.jpg'\n",
            " '../synthetic_dataset/images\\\\image_139.jpg'\n",
            " '../synthetic_dataset/images\\\\image_14.jpg'\n",
            " '../synthetic_dataset/images\\\\image_140.jpg'\n",
            " '../synthetic_dataset/images\\\\image_140.jpg'\n",
            " '../synthetic_dataset/images\\\\image_140.jpg'\n",
            " '../synthetic_dataset/images\\\\image_140.jpg'\n",
            " '../synthetic_dataset/images\\\\image_140.jpg'\n",
            " '../synthetic_dataset/images\\\\image_141.jpg'\n",
            " '../synthetic_dataset/images\\\\image_142.jpg'\n",
            " '../synthetic_dataset/images\\\\image_142.jpg'\n",
            " '../synthetic_dataset/images\\\\image_142.jpg'\n",
            " '../synthetic_dataset/images\\\\image_142.jpg'\n",
            " '../synthetic_dataset/images\\\\image_142.jpg'\n",
            " '../synthetic_dataset/images\\\\image_142.jpg'\n",
            " '../synthetic_dataset/images\\\\image_142.jpg'\n",
            " '../synthetic_dataset/images\\\\image_142.jpg'\n",
            " '../synthetic_dataset/images\\\\image_143.jpg'\n",
            " '../synthetic_dataset/images\\\\image_143.jpg'\n",
            " '../synthetic_dataset/images\\\\image_143.jpg'\n",
            " '../synthetic_dataset/images\\\\image_143.jpg'\n",
            " '../synthetic_dataset/images\\\\image_143.jpg'\n",
            " '../synthetic_dataset/images\\\\image_143.jpg'\n",
            " '../synthetic_dataset/images\\\\image_143.jpg'\n",
            " '../synthetic_dataset/images\\\\image_143.jpg'\n",
            " '../synthetic_dataset/images\\\\image_143.jpg'\n",
            " '../synthetic_dataset/images\\\\image_144.jpg'\n",
            " '../synthetic_dataset/images\\\\image_144.jpg'\n",
            " '../synthetic_dataset/images\\\\image_144.jpg'\n",
            " '../synthetic_dataset/images\\\\image_144.jpg'\n",
            " '../synthetic_dataset/images\\\\image_144.jpg'\n",
            " '../synthetic_dataset/images\\\\image_144.jpg'\n",
            " '../synthetic_dataset/images\\\\image_144.jpg'\n",
            " '../synthetic_dataset/images\\\\image_145.jpg'\n",
            " '../synthetic_dataset/images\\\\image_145.jpg'\n",
            " '../synthetic_dataset/images\\\\image_145.jpg'\n",
            " '../synthetic_dataset/images\\\\image_145.jpg'\n",
            " '../synthetic_dataset/images\\\\image_146.jpg'\n",
            " '../synthetic_dataset/images\\\\image_146.jpg'\n",
            " '../synthetic_dataset/images\\\\image_146.jpg'\n",
            " '../synthetic_dataset/images\\\\image_146.jpg'\n",
            " '../synthetic_dataset/images\\\\image_146.jpg'\n",
            " '../synthetic_dataset/images\\\\image_146.jpg'\n",
            " '../synthetic_dataset/images\\\\image_146.jpg'\n",
            " '../synthetic_dataset/images\\\\image_147.jpg'\n",
            " '../synthetic_dataset/images\\\\image_148.jpg'\n",
            " '../synthetic_dataset/images\\\\image_148.jpg'\n",
            " '../synthetic_dataset/images\\\\image_148.jpg'\n",
            " '../synthetic_dataset/images\\\\image_148.jpg'\n",
            " '../synthetic_dataset/images\\\\image_148.jpg'\n",
            " '../synthetic_dataset/images\\\\image_149.jpg'\n",
            " '../synthetic_dataset/images\\\\image_149.jpg'\n",
            " '../synthetic_dataset/images\\\\image_149.jpg'\n",
            " '../synthetic_dataset/images\\\\image_149.jpg'\n",
            " '../synthetic_dataset/images\\\\image_149.jpg'\n",
            " '../synthetic_dataset/images\\\\image_149.jpg'\n",
            " '../synthetic_dataset/images\\\\image_149.jpg'\n",
            " '../synthetic_dataset/images\\\\image_149.jpg'\n",
            " '../synthetic_dataset/images\\\\image_15.jpg'\n",
            " '../synthetic_dataset/images\\\\image_15.jpg'\n",
            " '../synthetic_dataset/images\\\\image_15.jpg'\n",
            " '../synthetic_dataset/images\\\\image_15.jpg'\n",
            " '../synthetic_dataset/images\\\\image_15.jpg'\n",
            " '../synthetic_dataset/images\\\\image_15.jpg'\n",
            " '../synthetic_dataset/images\\\\image_150.jpg'\n",
            " '../synthetic_dataset/images\\\\image_151.jpg'\n",
            " '../synthetic_dataset/images\\\\image_151.jpg'\n",
            " '../synthetic_dataset/images\\\\image_151.jpg'\n",
            " '../synthetic_dataset/images\\\\image_151.jpg'\n",
            " '../synthetic_dataset/images\\\\image_151.jpg'\n",
            " '../synthetic_dataset/images\\\\image_151.jpg'\n",
            " '../synthetic_dataset/images\\\\image_152.jpg'\n",
            " '../synthetic_dataset/images\\\\image_152.jpg'\n",
            " '../synthetic_dataset/images\\\\image_152.jpg'\n",
            " '../synthetic_dataset/images\\\\image_152.jpg'\n",
            " '../synthetic_dataset/images\\\\image_152.jpg'\n",
            " '../synthetic_dataset/images\\\\image_153.jpg'\n",
            " '../synthetic_dataset/images\\\\image_153.jpg'\n",
            " '../synthetic_dataset/images\\\\image_153.jpg'\n",
            " '../synthetic_dataset/images\\\\image_153.jpg'\n",
            " '../synthetic_dataset/images\\\\image_153.jpg'\n",
            " '../synthetic_dataset/images\\\\image_153.jpg'\n",
            " '../synthetic_dataset/images\\\\image_154.jpg'\n",
            " '../synthetic_dataset/images\\\\image_155.jpg'\n",
            " '../synthetic_dataset/images\\\\image_155.jpg'\n",
            " '../synthetic_dataset/images\\\\image_155.jpg'\n",
            " '../synthetic_dataset/images\\\\image_155.jpg'\n",
            " '../synthetic_dataset/images\\\\image_155.jpg'\n",
            " '../synthetic_dataset/images\\\\image_156.jpg'\n",
            " '../synthetic_dataset/images\\\\image_156.jpg'\n",
            " '../synthetic_dataset/images\\\\image_156.jpg'\n",
            " '../synthetic_dataset/images\\\\image_156.jpg'\n",
            " '../synthetic_dataset/images\\\\image_156.jpg'\n",
            " '../synthetic_dataset/images\\\\image_156.jpg'\n",
            " '../synthetic_dataset/images\\\\image_156.jpg'\n",
            " '../synthetic_dataset/images\\\\image_157.jpg'\n",
            " '../synthetic_dataset/images\\\\image_157.jpg'\n",
            " '../synthetic_dataset/images\\\\image_157.jpg'\n",
            " '../synthetic_dataset/images\\\\image_157.jpg'\n",
            " '../synthetic_dataset/images\\\\image_157.jpg'\n",
            " '../synthetic_dataset/images\\\\image_157.jpg'\n",
            " '../synthetic_dataset/images\\\\image_157.jpg'\n",
            " '../synthetic_dataset/images\\\\image_158.jpg'\n",
            " '../synthetic_dataset/images\\\\image_158.jpg'\n",
            " '../synthetic_dataset/images\\\\image_159.jpg'\n",
            " '../synthetic_dataset/images\\\\image_159.jpg'\n",
            " '../synthetic_dataset/images\\\\image_159.jpg'\n",
            " '../synthetic_dataset/images\\\\image_159.jpg'\n",
            " '../synthetic_dataset/images\\\\image_159.jpg'\n",
            " '../synthetic_dataset/images\\\\image_159.jpg'\n",
            " '../synthetic_dataset/images\\\\image_159.jpg'\n",
            " '../synthetic_dataset/images\\\\image_16.jpg'\n",
            " '../synthetic_dataset/images\\\\image_160.jpg'\n",
            " '../synthetic_dataset/images\\\\image_160.jpg'\n",
            " '../synthetic_dataset/images\\\\image_160.jpg'\n",
            " '../synthetic_dataset/images\\\\image_160.jpg'\n",
            " '../synthetic_dataset/images\\\\image_160.jpg'\n",
            " '../synthetic_dataset/images\\\\image_160.jpg'\n",
            " '../synthetic_dataset/images\\\\image_160.jpg'\n",
            " '../synthetic_dataset/images\\\\image_160.jpg'\n",
            " '../synthetic_dataset/images\\\\image_161.jpg'\n",
            " '../synthetic_dataset/images\\\\image_161.jpg'\n",
            " '../synthetic_dataset/images\\\\image_161.jpg'\n",
            " '../synthetic_dataset/images\\\\image_161.jpg'\n",
            " '../synthetic_dataset/images\\\\image_161.jpg'\n",
            " '../synthetic_dataset/images\\\\image_161.jpg'\n",
            " '../synthetic_dataset/images\\\\image_161.jpg'\n",
            " '../synthetic_dataset/images\\\\image_162.jpg'\n",
            " '../synthetic_dataset/images\\\\image_162.jpg'\n",
            " '../synthetic_dataset/images\\\\image_162.jpg'\n",
            " '../synthetic_dataset/images\\\\image_162.jpg'\n",
            " '../synthetic_dataset/images\\\\image_162.jpg'\n",
            " '../synthetic_dataset/images\\\\image_162.jpg'\n",
            " '../synthetic_dataset/images\\\\image_163.jpg'\n",
            " '../synthetic_dataset/images\\\\image_163.jpg'\n",
            " '../synthetic_dataset/images\\\\image_163.jpg'\n",
            " '../synthetic_dataset/images\\\\image_163.jpg'\n",
            " '../synthetic_dataset/images\\\\image_163.jpg'\n",
            " '../synthetic_dataset/images\\\\image_163.jpg'\n",
            " '../synthetic_dataset/images\\\\image_164.jpg'\n",
            " '../synthetic_dataset/images\\\\image_164.jpg'\n",
            " '../synthetic_dataset/images\\\\image_164.jpg'\n",
            " '../synthetic_dataset/images\\\\image_164.jpg'\n",
            " '../synthetic_dataset/images\\\\image_164.jpg'\n",
            " '../synthetic_dataset/images\\\\image_164.jpg'\n",
            " '../synthetic_dataset/images\\\\image_165.jpg'\n",
            " '../synthetic_dataset/images\\\\image_165.jpg'\n",
            " '../synthetic_dataset/images\\\\image_165.jpg'\n",
            " '../synthetic_dataset/images\\\\image_165.jpg'\n",
            " '../synthetic_dataset/images\\\\image_165.jpg'\n",
            " '../synthetic_dataset/images\\\\image_165.jpg'\n",
            " '../synthetic_dataset/images\\\\image_165.jpg'\n",
            " '../synthetic_dataset/images\\\\image_165.jpg'\n",
            " '../synthetic_dataset/images\\\\image_165.jpg'\n",
            " '../synthetic_dataset/images\\\\image_166.jpg'\n",
            " '../synthetic_dataset/images\\\\image_166.jpg'\n",
            " '../synthetic_dataset/images\\\\image_166.jpg'\n",
            " '../synthetic_dataset/images\\\\image_166.jpg'\n",
            " '../synthetic_dataset/images\\\\image_166.jpg'\n",
            " '../synthetic_dataset/images\\\\image_166.jpg'\n",
            " '../synthetic_dataset/images\\\\image_166.jpg'\n",
            " '../synthetic_dataset/images\\\\image_166.jpg'\n",
            " '../synthetic_dataset/images\\\\image_167.jpg'\n",
            " '../synthetic_dataset/images\\\\image_167.jpg'\n",
            " '../synthetic_dataset/images\\\\image_167.jpg'\n",
            " '../synthetic_dataset/images\\\\image_167.jpg'\n",
            " '../synthetic_dataset/images\\\\image_168.jpg'\n",
            " '../synthetic_dataset/images\\\\image_168.jpg'\n",
            " '../synthetic_dataset/images\\\\image_168.jpg'\n",
            " '../synthetic_dataset/images\\\\image_168.jpg'\n",
            " '../synthetic_dataset/images\\\\image_168.jpg'\n",
            " '../synthetic_dataset/images\\\\image_168.jpg'\n",
            " '../synthetic_dataset/images\\\\image_169.jpg'\n",
            " '../synthetic_dataset/images\\\\image_169.jpg'\n",
            " '../synthetic_dataset/images\\\\image_169.jpg'\n",
            " '../synthetic_dataset/images\\\\image_169.jpg'\n",
            " '../synthetic_dataset/images\\\\image_169.jpg'\n",
            " '../synthetic_dataset/images\\\\image_169.jpg'\n",
            " '../synthetic_dataset/images\\\\image_169.jpg'\n",
            " '../synthetic_dataset/images\\\\image_169.jpg'\n",
            " '../synthetic_dataset/images\\\\image_169.jpg'\n",
            " '../synthetic_dataset/images\\\\image_17.jpg'\n",
            " '../synthetic_dataset/images\\\\image_17.jpg'\n",
            " '../synthetic_dataset/images\\\\image_17.jpg'\n",
            " '../synthetic_dataset/images\\\\image_17.jpg'\n",
            " '../synthetic_dataset/images\\\\image_17.jpg'\n",
            " '../synthetic_dataset/images\\\\image_17.jpg'\n",
            " '../synthetic_dataset/images\\\\image_17.jpg'\n",
            " '../synthetic_dataset/images\\\\image_170.jpg'\n",
            " '../synthetic_dataset/images\\\\image_170.jpg'\n",
            " '../synthetic_dataset/images\\\\image_170.jpg'\n",
            " '../synthetic_dataset/images\\\\image_170.jpg'\n",
            " '../synthetic_dataset/images\\\\image_170.jpg'\n",
            " '../synthetic_dataset/images\\\\image_171.jpg'\n",
            " '../synthetic_dataset/images\\\\image_171.jpg'\n",
            " '../synthetic_dataset/images\\\\image_171.jpg'\n",
            " '../synthetic_dataset/images\\\\image_172.jpg'\n",
            " '../synthetic_dataset/images\\\\image_173.jpg'\n",
            " '../synthetic_dataset/images\\\\image_173.jpg'\n",
            " '../synthetic_dataset/images\\\\image_173.jpg'\n",
            " '../synthetic_dataset/images\\\\image_173.jpg'\n",
            " '../synthetic_dataset/images\\\\image_173.jpg'\n",
            " '../synthetic_dataset/images\\\\image_174.jpg'\n",
            " '../synthetic_dataset/images\\\\image_174.jpg'\n",
            " '../synthetic_dataset/images\\\\image_174.jpg'\n",
            " '../synthetic_dataset/images\\\\image_174.jpg'\n",
            " '../synthetic_dataset/images\\\\image_174.jpg'\n",
            " '../synthetic_dataset/images\\\\image_175.jpg'\n",
            " '../synthetic_dataset/images\\\\image_175.jpg'\n",
            " '../synthetic_dataset/images\\\\image_176.jpg'\n",
            " '../synthetic_dataset/images\\\\image_177.jpg'\n",
            " '../synthetic_dataset/images\\\\image_177.jpg'\n",
            " '../synthetic_dataset/images\\\\image_178.jpg'\n",
            " '../synthetic_dataset/images\\\\image_178.jpg'\n",
            " '../synthetic_dataset/images\\\\image_178.jpg'\n",
            " '../synthetic_dataset/images\\\\image_178.jpg'\n",
            " '../synthetic_dataset/images\\\\image_179.jpg'\n",
            " '../synthetic_dataset/images\\\\image_18.jpg'\n",
            " '../synthetic_dataset/images\\\\image_18.jpg'\n",
            " '../synthetic_dataset/images\\\\image_180.jpg'\n",
            " '../synthetic_dataset/images\\\\image_180.jpg'\n",
            " '../synthetic_dataset/images\\\\image_180.jpg'\n",
            " '../synthetic_dataset/images\\\\image_181.jpg'\n",
            " '../synthetic_dataset/images\\\\image_181.jpg'\n",
            " '../synthetic_dataset/images\\\\image_182.jpg'\n",
            " '../synthetic_dataset/images\\\\image_183.jpg'\n",
            " '../synthetic_dataset/images\\\\image_183.jpg'\n",
            " '../synthetic_dataset/images\\\\image_184.jpg'\n",
            " '../synthetic_dataset/images\\\\image_184.jpg'\n",
            " '../synthetic_dataset/images\\\\image_184.jpg'\n",
            " '../synthetic_dataset/images\\\\image_184.jpg'\n",
            " '../synthetic_dataset/images\\\\image_184.jpg'\n",
            " '../synthetic_dataset/images\\\\image_185.jpg'\n",
            " '../synthetic_dataset/images\\\\image_185.jpg'\n",
            " '../synthetic_dataset/images\\\\image_185.jpg'\n",
            " '../synthetic_dataset/images\\\\image_186.jpg'\n",
            " '../synthetic_dataset/images\\\\image_186.jpg'\n",
            " '../synthetic_dataset/images\\\\image_186.jpg'\n",
            " '../synthetic_dataset/images\\\\image_187.jpg'\n",
            " '../synthetic_dataset/images\\\\image_187.jpg'\n",
            " '../synthetic_dataset/images\\\\image_187.jpg'\n",
            " '../synthetic_dataset/images\\\\image_187.jpg'\n",
            " '../synthetic_dataset/images\\\\image_188.jpg'\n",
            " '../synthetic_dataset/images\\\\image_188.jpg'\n",
            " '../synthetic_dataset/images\\\\image_188.jpg'\n",
            " '../synthetic_dataset/images\\\\image_189.jpg'\n",
            " '../synthetic_dataset/images\\\\image_189.jpg'\n",
            " '../synthetic_dataset/images\\\\image_19.jpg'\n",
            " '../synthetic_dataset/images\\\\image_190.jpg'\n",
            " '../synthetic_dataset/images\\\\image_190.jpg'\n",
            " '../synthetic_dataset/images\\\\image_190.jpg'\n",
            " '../synthetic_dataset/images\\\\image_190.jpg'\n",
            " '../synthetic_dataset/images\\\\image_190.jpg'\n",
            " '../synthetic_dataset/images\\\\image_191.jpg'\n",
            " '../synthetic_dataset/images\\\\image_191.jpg'\n",
            " '../synthetic_dataset/images\\\\image_191.jpg'\n",
            " '../synthetic_dataset/images\\\\image_192.jpg'\n",
            " '../synthetic_dataset/images\\\\image_192.jpg'\n",
            " '../synthetic_dataset/images\\\\image_192.jpg'\n",
            " '../synthetic_dataset/images\\\\image_193.jpg'\n",
            " '../synthetic_dataset/images\\\\image_193.jpg'\n",
            " '../synthetic_dataset/images\\\\image_193.jpg'\n",
            " '../synthetic_dataset/images\\\\image_193.jpg'\n",
            " '../synthetic_dataset/images\\\\image_193.jpg'\n",
            " '../synthetic_dataset/images\\\\image_194.jpg'\n",
            " '../synthetic_dataset/images\\\\image_194.jpg'\n",
            " '../synthetic_dataset/images\\\\image_194.jpg'\n",
            " '../synthetic_dataset/images\\\\image_194.jpg'\n",
            " '../synthetic_dataset/images\\\\image_194.jpg'\n",
            " '../synthetic_dataset/images\\\\image_195.jpg'\n",
            " '../synthetic_dataset/images\\\\image_195.jpg'\n",
            " '../synthetic_dataset/images\\\\image_195.jpg'\n",
            " '../synthetic_dataset/images\\\\image_195.jpg'\n",
            " '../synthetic_dataset/images\\\\image_195.jpg'\n",
            " '../synthetic_dataset/images\\\\image_195.jpg'\n",
            " '../synthetic_dataset/images\\\\image_196.jpg'\n",
            " '../synthetic_dataset/images\\\\image_197.jpg'\n",
            " '../synthetic_dataset/images\\\\image_197.jpg'\n",
            " '../synthetic_dataset/images\\\\image_197.jpg'\n",
            " '../synthetic_dataset/images\\\\image_198.jpg'\n",
            " '../synthetic_dataset/images\\\\image_198.jpg'\n",
            " '../synthetic_dataset/images\\\\image_198.jpg'\n",
            " '../synthetic_dataset/images\\\\image_198.jpg'\n",
            " '../synthetic_dataset/images\\\\image_198.jpg'\n",
            " '../synthetic_dataset/images\\\\image_198.jpg'\n",
            " '../synthetic_dataset/images\\\\image_198.jpg'\n",
            " '../synthetic_dataset/images\\\\image_199.jpg'\n",
            " '../synthetic_dataset/images\\\\image_199.jpg'\n",
            " '../synthetic_dataset/images\\\\image_199.jpg'\n",
            " '../synthetic_dataset/images\\\\image_199.jpg'\n",
            " '../synthetic_dataset/images\\\\image_199.jpg'\n",
            " '../synthetic_dataset/images\\\\image_199.jpg'\n",
            " '../synthetic_dataset/images\\\\image_2.jpg'\n",
            " '../synthetic_dataset/images\\\\image_2.jpg'\n",
            " '../synthetic_dataset/images\\\\image_2.jpg'\n",
            " '../synthetic_dataset/images\\\\image_2.jpg'\n",
            " '../synthetic_dataset/images\\\\image_2.jpg'\n",
            " '../synthetic_dataset/images\\\\image_2.jpg'\n",
            " '../synthetic_dataset/images\\\\image_2.jpg'\n",
            " '../synthetic_dataset/images\\\\image_20.jpg'\n",
            " '../synthetic_dataset/images\\\\image_20.jpg'\n",
            " '../synthetic_dataset/images\\\\image_20.jpg'\n",
            " '../synthetic_dataset/images\\\\image_20.jpg'\n",
            " '../synthetic_dataset/images\\\\image_200.jpg'\n",
            " '../synthetic_dataset/images\\\\image_200.jpg'\n",
            " '../synthetic_dataset/images\\\\image_200.jpg'\n",
            " '../synthetic_dataset/images\\\\image_200.jpg'\n",
            " '../synthetic_dataset/images\\\\image_201.jpg'\n",
            " '../synthetic_dataset/images\\\\image_201.jpg'\n",
            " '../synthetic_dataset/images\\\\image_201.jpg'\n",
            " '../synthetic_dataset/images\\\\image_201.jpg'\n",
            " '../synthetic_dataset/images\\\\image_201.jpg'\n",
            " '../synthetic_dataset/images\\\\image_201.jpg'\n",
            " '../synthetic_dataset/images\\\\image_202.jpg'\n",
            " '../synthetic_dataset/images\\\\image_202.jpg'\n",
            " '../synthetic_dataset/images\\\\image_202.jpg'\n",
            " '../synthetic_dataset/images\\\\image_202.jpg'\n",
            " '../synthetic_dataset/images\\\\image_202.jpg'\n",
            " '../synthetic_dataset/images\\\\image_202.jpg'\n",
            " '../synthetic_dataset/images\\\\image_203.jpg'\n",
            " '../synthetic_dataset/images\\\\image_203.jpg'\n",
            " '../synthetic_dataset/images\\\\image_203.jpg'\n",
            " '../synthetic_dataset/images\\\\image_203.jpg'\n",
            " '../synthetic_dataset/images\\\\image_203.jpg'\n",
            " '../synthetic_dataset/images\\\\image_204.jpg'\n",
            " '../synthetic_dataset/images\\\\image_204.jpg'\n",
            " '../synthetic_dataset/images\\\\image_204.jpg'\n",
            " '../synthetic_dataset/images\\\\image_204.jpg'\n",
            " '../synthetic_dataset/images\\\\image_205.jpg'\n",
            " '../synthetic_dataset/images\\\\image_206.jpg'\n",
            " '../synthetic_dataset/images\\\\image_206.jpg'\n",
            " '../synthetic_dataset/images\\\\image_206.jpg'\n",
            " '../synthetic_dataset/images\\\\image_206.jpg'\n",
            " '../synthetic_dataset/images\\\\image_206.jpg'\n",
            " '../synthetic_dataset/images\\\\image_206.jpg'\n",
            " '../synthetic_dataset/images\\\\image_206.jpg'\n",
            " '../synthetic_dataset/images\\\\image_207.jpg'\n",
            " '../synthetic_dataset/images\\\\image_208.jpg'\n",
            " '../synthetic_dataset/images\\\\image_209.jpg'\n",
            " '../synthetic_dataset/images\\\\image_209.jpg'\n",
            " '../synthetic_dataset/images\\\\image_209.jpg'\n",
            " '../synthetic_dataset/images\\\\image_209.jpg'\n",
            " '../synthetic_dataset/images\\\\image_21.jpg'\n",
            " '../synthetic_dataset/images\\\\image_21.jpg'\n",
            " '../synthetic_dataset/images\\\\image_21.jpg'\n",
            " '../synthetic_dataset/images\\\\image_21.jpg'\n",
            " '../synthetic_dataset/images\\\\image_210.jpg'\n",
            " '../synthetic_dataset/images\\\\image_210.jpg'\n",
            " '../synthetic_dataset/images\\\\image_210.jpg'\n",
            " '../synthetic_dataset/images\\\\image_210.jpg'\n",
            " '../synthetic_dataset/images\\\\image_210.jpg'\n",
            " '../synthetic_dataset/images\\\\image_210.jpg'\n",
            " '../synthetic_dataset/images\\\\image_211.jpg'\n",
            " '../synthetic_dataset/images\\\\image_211.jpg'\n",
            " '../synthetic_dataset/images\\\\image_211.jpg'\n",
            " '../synthetic_dataset/images\\\\image_211.jpg'\n",
            " '../synthetic_dataset/images\\\\image_211.jpg'\n",
            " '../synthetic_dataset/images\\\\image_211.jpg'\n",
            " '../synthetic_dataset/images\\\\image_211.jpg'\n",
            " '../synthetic_dataset/images\\\\image_211.jpg'\n",
            " '../synthetic_dataset/images\\\\image_212.jpg'\n",
            " '../synthetic_dataset/images\\\\image_213.jpg'\n",
            " '../synthetic_dataset/images\\\\image_214.jpg'\n",
            " '../synthetic_dataset/images\\\\image_215.jpg'\n",
            " '../synthetic_dataset/images\\\\image_216.jpg'\n",
            " '../synthetic_dataset/images\\\\image_216.jpg'\n",
            " '../synthetic_dataset/images\\\\image_216.jpg'\n",
            " '../synthetic_dataset/images\\\\image_217.jpg'\n",
            " '../synthetic_dataset/images\\\\image_217.jpg'\n",
            " '../synthetic_dataset/images\\\\image_217.jpg'\n",
            " '../synthetic_dataset/images\\\\image_217.jpg'\n",
            " '../synthetic_dataset/images\\\\image_217.jpg'\n",
            " '../synthetic_dataset/images\\\\image_217.jpg'\n",
            " '../synthetic_dataset/images\\\\image_218.jpg'\n",
            " '../synthetic_dataset/images\\\\image_218.jpg'\n",
            " '../synthetic_dataset/images\\\\image_219.jpg'\n",
            " '../synthetic_dataset/images\\\\image_219.jpg'\n",
            " '../synthetic_dataset/images\\\\image_219.jpg'\n",
            " '../synthetic_dataset/images\\\\image_22.jpg'\n",
            " '../synthetic_dataset/images\\\\image_22.jpg'\n",
            " '../synthetic_dataset/images\\\\image_220.jpg'\n",
            " '../synthetic_dataset/images\\\\image_221.jpg'\n",
            " '../synthetic_dataset/images\\\\image_221.jpg'\n",
            " '../synthetic_dataset/images\\\\image_222.jpg'\n",
            " '../synthetic_dataset/images\\\\image_224.jpg'\n",
            " '../synthetic_dataset/images\\\\image_225.jpg'\n",
            " '../synthetic_dataset/images\\\\image_227.jpg'\n",
            " '../synthetic_dataset/images\\\\image_227.jpg'\n",
            " '../synthetic_dataset/images\\\\image_228.jpg'\n",
            " '../synthetic_dataset/images\\\\image_228.jpg'\n",
            " '../synthetic_dataset/images\\\\image_229.jpg'\n",
            " '../synthetic_dataset/images\\\\image_23.jpg'\n",
            " '../synthetic_dataset/images\\\\image_230.jpg'\n",
            " '../synthetic_dataset/images\\\\image_230.jpg'\n",
            " '../synthetic_dataset/images\\\\image_230.jpg'\n",
            " '../synthetic_dataset/images\\\\image_231.jpg'\n",
            " '../synthetic_dataset/images\\\\image_232.jpg'\n",
            " '../synthetic_dataset/images\\\\image_232.jpg'\n",
            " '../synthetic_dataset/images\\\\image_232.jpg'\n",
            " '../synthetic_dataset/images\\\\image_232.jpg'\n",
            " '../synthetic_dataset/images\\\\image_233.jpg'\n",
            " '../synthetic_dataset/images\\\\image_233.jpg'\n",
            " '../synthetic_dataset/images\\\\image_234.jpg'\n",
            " '../synthetic_dataset/images\\\\image_234.jpg'\n",
            " '../synthetic_dataset/images\\\\image_234.jpg'\n",
            " '../synthetic_dataset/images\\\\image_235.jpg'\n",
            " '../synthetic_dataset/images\\\\image_236.jpg'\n",
            " '../synthetic_dataset/images\\\\image_236.jpg'\n",
            " '../synthetic_dataset/images\\\\image_238.jpg'\n",
            " '../synthetic_dataset/images\\\\image_241.jpg'\n",
            " '../synthetic_dataset/images\\\\image_245.jpg'\n",
            " '../synthetic_dataset/images\\\\image_245.jpg'\n",
            " '../synthetic_dataset/images\\\\image_253.jpg'\n",
            " '../synthetic_dataset/images\\\\image_255.jpg'\n",
            " '../synthetic_dataset/images\\\\image_259.jpg'\n",
            " '../synthetic_dataset/images\\\\image_26.jpg'\n",
            " '../synthetic_dataset/images\\\\image_26.jpg']\n"
          ]
        }
      ],
      "source": [
        "#split the data in 1/5\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "train_index, test_index = next( skf.split(img_names, Y) )\n",
        "\n",
        "#Store the images according to where they are going to be moved\n",
        "X_train, X_test = img_names[train_index], img_names[test_index]\n",
        "Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "# Show the images and the destination folder\n",
        "print(\"Images to be moved to Train Folder: \\n\", X_train)\n",
        "print(\"\\n Images to be moved to Test Folder: \\n\", X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAWGq8yEy0oD"
      },
      "source": [
        "### Train Dataset & Test Dataset\n",
        "Once we have stored the images destined for the train data set and which ones are destined for the test data set, we proceed to create said directories and move each image respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jek3AdF00Mte"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully created the directory ../synthetic_dataset/train \n",
            "Successfully created the directory ../synthetic_dataset/test \n"
          ]
        }
      ],
      "source": [
        "TRAIN_PATH = \"../synthetic_dataset/train\"\n",
        "TEST_PATH = \"../synthetic_dataset/test\" \n",
        "\n",
        "#Create the folders for train and test\n",
        "try:\n",
        "    os.mkdir(TRAIN_PATH)\n",
        "except OSError:\n",
        "    print (\"Creation of the directory %s failed\" % TRAIN_PATH)\n",
        "else:\n",
        "    print (\"Successfully created the directory %s \" % TRAIN_PATH)\n",
        "\n",
        "try:\n",
        "    os.mkdir(TEST_PATH)\n",
        "except OSError:\n",
        "    print (\"Creation of the directory %s failed\" % TEST_PATH)\n",
        "else:\n",
        "    print (\"Successfully created the directory %s \" % TEST_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GQWCtj6gzWlt"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 524/524 [07:29<00:00,  1.17it/s]\n",
            "100%|| 159/159 [02:18<00:00,  1.14it/s]\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "from tqdm import tqdm\n",
        "# Transform both arrays into lists to avoid duplicate images in the folders\n",
        "X_train= list(dict.fromkeys(X_train))\n",
        "X_test= list(dict.fromkeys(X_test))\n",
        "\n",
        "# Copy the specific images to the train folder\n",
        "for f in tqdm(range(len(X_train))):\n",
        "    if os.path.isfile(X_train[f]):\n",
        "        #Recorremos el folder donde se almacenan los .json\n",
        "        for file_name in [file for file in os.listdir(JSON_PATH)]:\n",
        "            with open(os.path.join(JSON_PATH,file_name)) as json_file:\n",
        "                content= json.load(json_file)\n",
        "                #Almacenamos con que imagen va relacionado\n",
        "                jpegname= content['imagePath']\n",
        "                full_jpegname= IMG_PATH + jpegname\n",
        "                if full_jpegname == X_train[f]:\n",
        "                    full_json_name= JSON_PATH + file_name\n",
        "                    shutil.copy(full_json_name,TRAIN_PATH)\n",
        "        shutil.copy(X_train[f],TRAIN_PATH)\n",
        "\n",
        "\n",
        "#And to the test folder\n",
        "for f in tqdm(range(len(X_test))):\n",
        "    if (os.path.isfile(X_test[f])):\n",
        "        #Recorremos el folder donde se almacenan los .json\n",
        "        for file_name in [file for file in os.listdir(JSON_PATH)]:\n",
        "            with open(os.path.join(JSON_PATH,file_name)) as json_file:\n",
        "                content= json.load(json_file)\n",
        "                #Almacenamos con que imagen va relacionado\n",
        "                jpegname= content['imagePath']\n",
        "                full_jpegname= IMG_PATH + jpegname\n",
        "                if full_jpegname == X_test[f]:\n",
        "                    full_json_name= JSON_PATH + file_name\n",
        "                    shutil.copy(full_json_name,TEST_PATH)\n",
        "        shutil.copy(X_test[f],TEST_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJDQEUHw5KEb"
      },
      "source": [
        "## **MASK R-CNN for Instance Segmentation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPeVg8Hfz3bH"
      },
      "source": [
        "1. First of all, we copy the MASK R-CNN repository and download the dataset in COCO format.\n",
        "\n",
        "2. Later we import all the necessary libraries, and define the routes of both the repository and the dataset to be able to access it later.\n",
        "\n",
        "3. Since we have trained our network locally, we proceed to download the trained weights to be able to evaluate them next."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I063Ctb4DMcw"
      },
      "source": [
        "### **Initialization**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2TzSKbzBkVG"
      },
      "source": [
        "#### **Definicion de Rutas y Librerias**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OGUzmLPpB4J",
        "outputId": "84b714f7-438f-4c26-92f5-79ddd7d0b38b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from PIL import Image, ImageDraw\n",
        "from tensorflow.python.framework.versions import VERSION as __version__\n",
        "import tensorflow as tf\n",
        "import imgaug\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "#Cambiamos el Directorio al propio de MASK_RCNN\n",
        "ROOT_DIR = '.'\n",
        "assert os.path.exists(ROOT_DIR), 'ROOT_DIR does not exist'\n",
        "\n",
        "# Import mrcnn libraries\n",
        "sys.path.append(ROOT_DIR)\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "from mrcnn.model import log\n",
        "\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "# Directorio perteneciente a MASK-RCNN\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Ruta al archivo de pesos\n",
        "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_debris_weights.h5\")\n",
        "\n",
        "# Descargamos los Pesos Entrenados de COCO\n",
        "if not os.path.exists(COCO_WEIGHTS_PATH):\n",
        "    utils.download_trained_weights(COCO_WEIGHTS_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch0rdplzBsP9"
      },
      "source": [
        "#### **Configuracion del Entrenamiento**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqRhRkSzo8m1",
        "outputId": "ee331f7b-bdd1-4cf0-953e-c18dc12df0ea"
      },
      "outputs": [],
      "source": [
        "############################################################\n",
        "#  Configuracion\n",
        "############################################################\n",
        "\n",
        "class CleanSeaConfig(Config):\n",
        "    \"\"\"\n",
        "    Configuracion para el entrenamiento con CleanSea Dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    # Nombre de la configuracion\n",
        "    NAME = \"debris\"\n",
        "\n",
        "    # We use a GPU with 12GB memory, which can fit two images.\n",
        "    # Adjust down if you use a smaller GPU.\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "    # Use small images for faster training. Set the limits of the small side\n",
        "    # the large side, and that determines the image shape.\n",
        "    IMAGE_MIN_DIM = 512\n",
        "    IMAGE_MAX_DIM = 512\n",
        "\n",
        "    # Numero de clases + el background\n",
        "    NUM_CLASSES = 1 + 19  # Cleansea tiene 19 clases\n",
        "\n",
        "    # Numero de pasos por epoca en el entrenamiento\n",
        "    #STEPS_PER_EPOCH = 100\n",
        "    \n",
        "    # Salta las detecciones con <90% de seguridad\n",
        "    DETECTION_MIN_CONFIDENCE = 0.5\n",
        "\n",
        "    LEARNING_RATE = 0.001\n",
        "    \n",
        "\n",
        "config= CleanSeaConfig()\n",
        "config.display()\n",
        "\n",
        "def get_ax(rows=1, cols=1, size=8):\n",
        "    \"\"\"Return a Matplotlib Axes array to be used in\n",
        "    all visualizations in the notebook. Provide a\n",
        "    central point to control graph sizes.\n",
        "\n",
        "    Change the default size attribute to control the size\n",
        "    of rendered images\n",
        "    \"\"\"\n",
        "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
        "    return ax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEklggs-CCHp"
      },
      "source": [
        "#### **Configuracion del Dataset**\n",
        "\n",
        "Se realiza una carga de todas las imagenes y anotaciones necesarias para aplicar las mascaras durante la deteccion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XohdwgOwo5gF"
      },
      "outputs": [],
      "source": [
        "############################################################\n",
        "#  Dataset\n",
        "############################################################\n",
        "\n",
        "class CleanSeaDataset(utils.Dataset):\n",
        "    def load_data(self, dataset_dir, subset):\n",
        "        # Train or validation dataset?\n",
        "        assert subset in [\"train_coco_ok\", \"test_coco_ok\"]\n",
        "        dataset_dir = os.path.join(dataset_dir, subset)\n",
        "        print(dataset_dir)\n",
        "\n",
        "        # Cargamos el archivo json\n",
        "        annotation_json = os.path.join(dataset_dir,\"annotations.json\")\n",
        "        json_file = open(annotation_json)\n",
        "        coco_json = json.load(json_file)\n",
        "        json_file.close()\n",
        "        print(\"\\nAnotaciones Cargadas\\n\")\n",
        "\n",
        "        # Aadimos los nombres de las clases usando el metodo de utils.Dataset\n",
        "        source_name = \"coco_like\"\n",
        "        for category in coco_json['categories']:\n",
        "            class_id = category['id']\n",
        "            class_name = category['name']\n",
        "            if class_id < 1:\n",
        "                print('Error: Class id for \"{}\" reserved for the background'.format(class_name))\n",
        "            else:\n",
        "                self.add_class(source_name, class_id, class_name)\n",
        "        print(\"Nombres Aadidos \\n\")\n",
        "\n",
        "        # Almacenamos las anotaciones\n",
        "        annotations = {}\n",
        "        for annotation in coco_json['annotations']:\n",
        "            image_id = annotation['image_id']\n",
        "            if image_id not in annotations:\n",
        "                annotations[image_id] = []\n",
        "            annotations[image_id].append(annotation)\n",
        "        print(\"Anotaciones Almacenadas\\n\")\n",
        "\n",
        "        # Almacenamos las imagenes y las aadimos al dataset\n",
        "        seen_images = {}\n",
        "        for image in coco_json['images']:\n",
        "            image_id = image['id']\n",
        "            if image_id in seen_images:\n",
        "                print(\"Warning: Skipping duplicate image id: {}\".format(image))\n",
        "            else:\n",
        "                seen_images[image_id] = image\n",
        "                try:\n",
        "                    image_file_name = image['file_name']\n",
        "                    image_width = image['width']\n",
        "                    image_height = image['height']\n",
        "                except KeyError as key:\n",
        "                    print(\"Warning: Skipping image (id: {}) with missing key: {}\".format(image_id, key))\n",
        "                \n",
        "                image_path = os.path.join(dataset_dir, image_file_name)\n",
        "                image_annotations = annotations[image_id]\n",
        "                \n",
        "                # Aadimos la imagen usando el metodo de utils.Dataset\n",
        "                self.add_image(\n",
        "                    source=source_name,\n",
        "                    image_id=image_id,\n",
        "                    path=image_path,\n",
        "                    width=image_width,\n",
        "                    height=image_height,\n",
        "                    annotations=image_annotations\n",
        "                )\n",
        "        print(\"Imagenes aadidas al Dataset\\n\")\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\" Carga la mascara de instancia para la imagen dada\n",
        "        MaskRCNN espera mascaras en forma de mapa de bits (altura, anchura e instancias)\n",
        "        Argumentos:\n",
        "            image_id: El ID de la imagen a la que vamos a cargar la mascara\n",
        "        Salida:\n",
        "            masks: Una cadena booleana con estructura (altura, anchya y la cuenta de instancias) con una mascara por instancia\n",
        "            class_ids: Una cadena de 1 dimension de clase ID de la instancia de la mascara \"\"\"\n",
        "        image_info = self.image_info[image_id]\n",
        "        annotations = image_info['annotations']\n",
        "        instance_masks = []\n",
        "        class_ids = []\n",
        "        \n",
        "        for annotation in annotations:\n",
        "            class_id = annotation['category_id']\n",
        "            mask = Image.new('1', (image_info['width'], image_info['height']))\n",
        "            mask_draw = ImageDraw.ImageDraw(mask, '1')\n",
        "            for segmentation in annotation['segmentation']:\n",
        "                mask_draw.polygon(segmentation, fill=1)\n",
        "                bool_array = np.array(mask) > 0\n",
        "                instance_masks.append(bool_array)\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "        mask = np.dstack(instance_masks)\n",
        "        class_ids = np.array(class_ids, dtype=np.int32)\n",
        "        return mask, class_ids\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the path of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"object\":\n",
        "            return info[\"path\"]\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_vMOT4mQaq8"
      },
      "source": [
        "Inicializamos los datasets para el entrenamiento y la validacion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AagKz7yCRRc"
      },
      "source": [
        "#### **Inicializacion y Configuracion de los Conjuntos de Entrenamiento y Validacion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-pCk3G9qtAN",
        "outputId": "c30d3d80-da52-4e06-a4c8-5a8f793095ac"
      },
      "outputs": [],
      "source": [
        "\"\"\"Train the model.\"\"\"\n",
        "# Training dataset.\n",
        "dataset_train = CleanSeaDataset()\n",
        "print(\"Configuracion para train cargada\\n\")\n",
        "dataset_train.load_data(\"/content\",\"train_coco_ok\")\n",
        "print(\"Dataset Inicializado Correctamente\\n\")\n",
        "dataset_train.prepare()\n",
        "print(\"Preparacion del Dataset Completada\\n\")\n",
        "\n",
        "# Validation dataset\n",
        "dataset_test = CleanSeaDataset()\n",
        "print(\"Configuracion para test cargada\\n\")\n",
        "dataset_test.load_data(\"/content\", \"test_coco_ok\")\n",
        "print(\"Dataset Inicializado Correctamente\\n\")\n",
        "dataset_test.prepare()\n",
        "print(\"Preparacion del Dataset Completada\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJn5TBK3CXn_"
      },
      "source": [
        "##### **Ejemplos de la aplicacion de las mascaras sobre las imagenes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKp7no977YXx",
        "outputId": "1206abc0-1192-4aef-e064-406876b61140"
      },
      "outputs": [],
      "source": [
        "print(\"Mostrando Imagenes aleatorias...\\n\")\n",
        "\n",
        "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
        "for image_id in image_ids:\n",
        "    image = dataset_train.load_image(image_id)\n",
        "    mask, class_ids = dataset_train.load_mask(image_id)\n",
        "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp9YoapgQ14Q"
      },
      "source": [
        "#### **Inicializacion del modelo para entrenamiento**\n",
        "Una vez hemos comprobado que se aplican bien las mscaras, podemos comenzar a entrenar la red. Para ello inicializaremos el modelo para entrenamiento y seleccionaremos los pesos con los que queremos entrenar la red.\n",
        "\n",
        "Como no tenemos pesos entrenados inicialmente, utilizaremos los pesos predeterminados de coco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6BrcXfj8hQ2",
        "outputId": "22f3c590-87b3-49be-dc7a-82c24da744f0"
      },
      "outputs": [],
      "source": [
        "print(\"Inicializando modelo para entrenamiento...\\n\")\n",
        "model=modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)\n",
        "# Which weights to start with?\n",
        "init_with = \"coco\"  # imagenet, coco, or last\n",
        "\n",
        "if init_with == \"imagenet\":\n",
        "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
        "elif init_with == \"coco\":\n",
        "    # Load weights trained on MS COCO, but skip layers that\n",
        "    # are different due to the different number of classes\n",
        "    # See README for instructions to download the COCO weights\n",
        "    model.load_weights(COCO_WEIGHTS_PATH, by_name=True,\n",
        "                    exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "elif init_with == \"last\":\n",
        "    # Load the last model you trained and continue training\n",
        "    model.load_weights(model.find_last(), by_name=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QkzvxgHC2S2"
      },
      "source": [
        "### **Entrenamiento del modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt_03vD_FRz1",
        "outputId": "f46a1490-951e-486c-f879-7330126160ef"
      },
      "outputs": [],
      "source": [
        "############################################################\n",
        "#  Entrenamiento\n",
        "############################################################\n",
        "# ===============================================================================\n",
        "# Aumentado de Datos\n",
        "# ===============================================================================\n",
        "from imgaug import augmenters as iaa\n",
        "SAVE_PATH = '/content/drive/MyDrive/Project_CleanSea/Logs'\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5), # horizontal flips\n",
        "    # Small gaussian blur with random sigma between 0 and 0.5.\n",
        "    # But we only blur about 50% of all images.\n",
        "    iaa.Sometimes(\n",
        "        0.5,\n",
        "        iaa.GaussianBlur(sigma=(0, 0.5))\n",
        "    ),\n",
        "    # Strengthen or weaken the contrast in each image.\n",
        "    iaa.LinearContrast((0.75, 1.5)),\n",
        "    # Make some images brighter and some darker.\n",
        "    # In 20% of all cases, we sample the multiplier once per channel,\n",
        "    # which can end up changing the color of the images.\n",
        "    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
        "    # Apply affine transformations to each image.\n",
        "    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
        "    iaa.Affine(\n",
        "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
        "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "        rotate=(-25, 25),\n",
        "        shear=(-8, 8)\n",
        "    )\n",
        "], random_order=True) # apply augmenters in random order\n",
        "\n",
        "# ===============================================================================\n",
        "\n",
        "# Train the head branches\n",
        "# Passing layers=\"heads\" freezes all layers except the head\n",
        "# layers. You can also pass a regular expression to select\n",
        "# which layers to train by name pattern.\n",
        "\n",
        "print(\"Entrenando Heads...\\n\")\n",
        "model.train(dataset_train, dataset_test, learning_rate=config.LEARNING_RATE, epochs=2, layers='heads',augmentation=seq)\n",
        "\n",
        "# Fine tune all layers\n",
        "# Passing layers=\"all\" trains all layers. You can also \n",
        "# pass a regular expression to select which layers to\n",
        "# train by name pattern.\n",
        "\n",
        "# Aadimos aumentado de imagenes\n",
        "# Giramos las imagenes el 50% de las veces\n",
        "#aumentado = imgaug.augmenters.Fliplr(0.5)\n",
        "#augmentation = aumentado\n",
        "print(\"Entrenando extensivamente...\\n\")\n",
        "model.train(dataset_train, dataset_test, \n",
        "            learning_rate=config.LEARNING_RATE / 10,\n",
        "            epochs=10, \n",
        "            layers=\"all\",augmentation=seq)\n",
        "\n",
        "# Save weights\n",
        "# Typically not needed because callbacks save after every epoch\n",
        "# Uncomment to save manually\n",
        "print(\"Guardando Pesos...\\n\")\n",
        "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_debris_weights.h5\")\n",
        "model.keras_model.save_weights(model_path)\n",
        "print(\"Pesos Guardados en mask_rcnn_debris_weights.h2\")\n",
        "#!tensorboard dev upload --logdir /content/Mask_RCNN-tensorflow2.0/logs\n",
        "shutil.move(model_path,SAVE_PATH)\n",
        "print(\"Logs Almacenados en Drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBnxfuE_C9yB"
      },
      "source": [
        "### **Validacion del modelo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Aho3nhCMowl"
      },
      "source": [
        "#### **Evaluacion con Pesos entrenados (25 Epocas)** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "kXaE7oSIMsww",
        "outputId": "f4395b53-2013-4923-d998-0f070fa47aa0"
      },
      "outputs": [],
      "source": [
        "############################################################\n",
        "#  Evaluacion\n",
        "############################################################\n",
        "#Descargamos los pesos entrenados de forma local\n",
        "%cd /content/Mask_RCNN-tensorflow2.0/\n",
        "!gdown https://drive.google.com/uc?id=1iY-jFwRv1LHL7ItqQ9HfZ_R4dONMXYx8\n",
        "class InferenceConfig(CleanSeaConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    USE_MINI_MASK = False\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", \n",
        "                          config=inference_config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "\n",
        "# Get path to saved weights\n",
        "# Either set a specific path or find last trained weights\n",
        "model_path = os.path.join(ROOT_DIR, \"mask_rcnn_debris_weights2505.h5\")\n",
        "#model_path = model.find_last()\n",
        "\n",
        "# Load trained weights\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)\n",
        "\n",
        "# Test on a random image\n",
        "image_id = random.choice(dataset_test.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_test, inference_config, \n",
        "                           image_id)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "7c_iHk5tMwT1",
        "outputId": "09ec0f62-cd10-412d-98f1-d91a033d7452"
      },
      "outputs": [],
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_test.class_names, r['scores'], ax=get_ax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "OKWsO2Y9M1cS",
        "outputId": "ed58e611-8448-4ea5-ae6e-b982e6a47e22"
      },
      "outputs": [],
      "source": [
        "# Test on a random image\n",
        "image_id = random.choice(dataset_test.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_test, inference_config, \n",
        "                           image_id)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "rMUufc18M7gA",
        "outputId": "c56b8c3b-c8ad-4848-cf79-91b133898790"
      },
      "outputs": [],
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_test.class_names, r['scores'], ax=get_ax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZUSitsbM_Ok",
        "outputId": "a2a514b0-0454-495c-d29b-0880fa731dea"
      },
      "outputs": [],
      "source": [
        "# Compute VOC-Style mAP @ IoU=0.5\n",
        "image_ids = dataset_test.image_ids\n",
        "APs = []\n",
        "for image_id in image_ids:\n",
        "    # Load image and ground truth data\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset_test, inference_config,\n",
        "                               image_id)\n",
        "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
        "    # Run object detection\n",
        "    results = model.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "    # Compute AP\n",
        "    AP, precisions, recalls, overlaps =\\\n",
        "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "    \n",
        "    APs.append(AP)\n",
        "\n",
        "print(\"mAP: \", np.mean(APs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbnalzXScdy0"
      },
      "source": [
        "#### **Evaluacion con Pesos entrenados (50 Epocas)** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "e7F8KymdcqB0",
        "outputId": "a4910893-c74f-4ea9-ed96-3512c0f1d4b4"
      },
      "outputs": [],
      "source": [
        "############################################################\n",
        "#  Evaluacion\n",
        "############################################################\n",
        "#Descargamos los pesos entrenados de forma local\n",
        "%cd /content/Mask_RCNN-tensorflow2.0/\n",
        "!gdown https://drive.google.com/uc?id=1iIBS1_jHmtSa5gKghDIgIvuCN5GgvtUF\n",
        "class InferenceConfig(CleanSeaConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    USE_MINI_MASK = False\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", \n",
        "                          config=inference_config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "\n",
        "# Get path to saved weights\n",
        "# Either set a specific path or find last trained weights\n",
        "model_path = os.path.join(ROOT_DIR, \"mask_rcnn_debris_weights50.h5\")\n",
        "#model_path = model.find_last()\n",
        "\n",
        "# Load trained weights\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)\n",
        "\n",
        "# Test on a random image\n",
        "image_id = random.choice(dataset_test.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_test, inference_config, \n",
        "                           image_id)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "tKWy1BF8ctYp",
        "outputId": "c256feb9-d358-4a2b-f7d3-82fcfe39d263"
      },
      "outputs": [],
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_test.class_names, r['scores'], ax=get_ax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "emOEctwBc3o_",
        "outputId": "60766b9c-1c2f-40cb-f7f5-751ed6903d9f"
      },
      "outputs": [],
      "source": [
        "# Test on a random image\n",
        "image_id = random.choice(dataset_test.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_test, inference_config, \n",
        "                           image_id)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "IaRkBrxcBeXb",
        "outputId": "785a75c6-fd99-4fd6-aec9-1a1ecd15c9c8"
      },
      "outputs": [],
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_test.class_names, r['scores'], ax=get_ax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozO2-2T5BowK",
        "outputId": "beec2c73-b746-4e1e-ec16-07078274d491"
      },
      "outputs": [],
      "source": [
        "# Compute VOC-Style mAP @ IoU=0.5\n",
        "image_ids = dataset_test.image_ids\n",
        "APs = []\n",
        "for image_id in image_ids:\n",
        "    # Load image and ground truth data\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset_test, inference_config,\n",
        "                               image_id)\n",
        "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
        "    # Run object detection\n",
        "    results = model.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "    # Compute AP\n",
        "    AP, precisions, recalls, overlaps =\\\n",
        "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "    \n",
        "    APs.append(AP)\n",
        "\n",
        "print(\"mAP: \", np.mean(APs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6aRvrzsBtWM"
      },
      "source": [
        "#### **Evaluacion con Pesos entrenados (75 Epocas)** \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "wAhb5P_mB3Mv",
        "outputId": "d204691c-5395-49a3-fb20-68223be22daa"
      },
      "outputs": [],
      "source": [
        "############################################################\n",
        "#  Evaluacion\n",
        "############################################################\n",
        "#Descargamos los pesos entrenados de forma local\n",
        "%cd /content/Mask_RCNN-tensorflow2.0/\n",
        "!gdown https://drive.google.com/uc?id=141SZd-LzJJs0Mwq7W7PNyPz-BC4pqWab\n",
        "class InferenceConfig(CleanSeaConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    USE_MINI_MASK = False\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", \n",
        "                          config=inference_config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "\n",
        "# Get path to saved weights\n",
        "# Either set a specific path or find last trained weights\n",
        "model_path = os.path.join(ROOT_DIR, \"mask_rcnn_debris_weights7505.h5\")\n",
        "#model_path = model.find_last()\n",
        "\n",
        "# Load trained weights\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)\n",
        "\n",
        "# Test on a random image\n",
        "image_id = random.choice(dataset_test.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_test, inference_config, \n",
        "                           image_id)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "sgw7Hqo-B8I2",
        "outputId": "d147e09c-eea5-4bdd-b72f-91e169a37de8"
      },
      "outputs": [],
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_test.class_names, r['scores'], ax=get_ax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "rcASLSNYB-hE",
        "outputId": "b98f6214-4779-4358-8961-8ea6c7602584"
      },
      "outputs": [],
      "source": [
        "# Test on a random image\n",
        "image_id = random.choice(dataset_test.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_test, inference_config, \n",
        "                           image_id)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "SCphC00CCBQT",
        "outputId": "2a0d391e-0a48-4ac0-db56-ee71c225cc75"
      },
      "outputs": [],
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_test.class_names, r['scores'], ax=get_ax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN5VRXzdCDLZ",
        "outputId": "cd82c2f4-80bf-4212-b075-cf0c06c93b24"
      },
      "outputs": [],
      "source": [
        "# Compute VOC-Style mAP @ IoU=0.5\n",
        "image_ids = dataset_test.image_ids\n",
        "APs = []\n",
        "for image_id in image_ids:\n",
        "    # Load image and ground truth data\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset_test, inference_config,\n",
        "                               image_id)\n",
        "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
        "    # Run object detection\n",
        "    results = model.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "    # Compute AP\n",
        "    AP, precisions, recalls, overlaps =\\\n",
        "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "    APs.append(AP)\n",
        "    \n",
        "print(\"mAP: \", np.mean(APs))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZd_I2HgzEUX"
      },
      "source": [
        "#### **Evaluacion con Pesos entrenados (100 Epocas)** \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "id": "JUmHowEWzLoF",
        "outputId": "022298c6-1ebb-4318-edcd-b88d19bff626"
      },
      "outputs": [],
      "source": [
        "############################################################\n",
        "#  Evaluacion\n",
        "############################################################\n",
        "#Descargamos los pesos entrenados de forma local\n",
        "%cd /content/Mask_RCNN-tensorflow2.0/\n",
        "!gdown https://drive.google.com/uc?id=1AfpFadG5-xYgkyfwNwDT4XCtRvhHPWAt\n",
        "\n",
        "class InferenceConfig(CleanSeaConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    USE_MINI_MASK = False\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", \n",
        "                          config=inference_config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "\n",
        "# Get path to saved weights\n",
        "# Either set a specific path or find last trained weights\n",
        "model_path = os.path.join(ROOT_DIR, \"mask_rcnn_debris_weights10005.h5\")\n",
        "#model_path = model.find_last()\n",
        "\n",
        "# Load trained weights\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)\n",
        "\n",
        "# Test on a random image\n",
        "image_id = random.choice(dataset_test.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_test, inference_config, \n",
        "                           image_id)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "Y4xaNk93zSRC",
        "outputId": "f41bdf0a-3287-4c52-e8a3-de00912dbd73"
      },
      "outputs": [],
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_test.class_names, r['scores'], ax=get_ax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "nyYPum72zUnv",
        "outputId": "762ef178-e4b3-4d53-a956-dc663b8356dd"
      },
      "outputs": [],
      "source": [
        "# Test on a random image\n",
        "image_id = random.choice(dataset_test.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_test, inference_config, \n",
        "                           image_id)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "5cflgz7MzW4t",
        "outputId": "717f77d8-678f-4dce-9d75-00989a9b955d"
      },
      "outputs": [],
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_test.class_names, r['scores'], ax=get_ax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmFIOsASzZb5",
        "outputId": "550be863-6807-423e-ee7c-d1b0a8f842c8"
      },
      "outputs": [],
      "source": [
        "# Compute VOC-Style mAP @ IoU=0.5\n",
        "image_ids = dataset_test.image_ids\n",
        "APs = []\n",
        "for image_id in image_ids:\n",
        "    # Load image and ground truth data\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset_test, inference_config,\n",
        "                               image_id)\n",
        "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
        "    # Run object detection\n",
        "    results = model.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "    # Compute AP\n",
        "    AP, precisions, recalls, overlaps =\\\n",
        "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "    APs.append(AP)\n",
        "    \n",
        "print(\"mAP: \", np.mean(APs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D-QFt8AOWCi"
      },
      "source": [
        "#### **Evaluacion con Pesos entrenados (200 Epocas)** \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "8AmQ5kiDOgXp",
        "outputId": "d320c185-c17c-444a-b6e2-6b5d2f71fd6e"
      },
      "outputs": [],
      "source": [
        "############################################################\n",
        "#  Evaluacion\n",
        "############################################################\n",
        "#Descargamos los pesos entrenados de forma local\n",
        "%cd /content/Mask_RCNN-tensorflow2.0/\n",
        "!gdown https://drive.google.com/uc?id=1WPRhFbBMZKVQMidUSoSRjv0QCaaw-Dab\n",
        "\n",
        "class InferenceConfig(CleanSeaConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    USE_MINI_MASK = False\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", \n",
        "                          config=inference_config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "\n",
        "# Get path to saved weights\n",
        "# Either set a specific path or find last trained weights\n",
        "model_path = os.path.join(ROOT_DIR, \"mask_rcnn_debris_weights20005.h5\")\n",
        "#model_path = model.find_last()\n",
        "\n",
        "# Load trained weights\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)\n",
        "\n",
        "# Test on a random image\n",
        "image_id = random.choice(dataset_test.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_test, inference_config, \n",
        "                           image_id)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "am66nHbVO2x5",
        "outputId": "a334eef0-e0b7-4fc2-b89b-9944474f35f5"
      },
      "outputs": [],
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_test.class_names, r['scores'], ax=get_ax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "HJqiZR7HO5k3",
        "outputId": "e0ea6105-5448-4e72-97dd-cfb5945272f4"
      },
      "outputs": [],
      "source": [
        "# Test on a random image\n",
        "image_id = random.choice(dataset_test.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_test, inference_config, \n",
        "                           image_id)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "zR2hJ6tDO-jm",
        "outputId": "5598e5c1-57a4-4869-b14f-102b5afc483a"
      },
      "outputs": [],
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_test.class_names, r['scores'], ax=get_ax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jU50AMoqPBcE",
        "outputId": "7b49c1b6-7154-412c-d527-046a1ecfe8bb"
      },
      "outputs": [],
      "source": [
        "# Compute VOC-Style mAP @ IoU=0.5\n",
        "image_ids = dataset_test.image_ids\n",
        "APs = []\n",
        "for image_id in image_ids:\n",
        "    # Load image and ground truth data\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset_test, inference_config,\n",
        "                               image_id)\n",
        "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
        "    # Run object detection\n",
        "    results = model.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "    # Compute AP\n",
        "    AP, precisions, recalls, overlaps =\\\n",
        "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "    APs.append(AP)\n",
        "    \n",
        "print(\"mAP: \", np.mean(APs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndVGEHodN9G3"
      },
      "source": [
        "#### **Evaluacion con Pesos entrenados y ligero aumentado de Datos(200 Epocas)** \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "iCon8rjRN8dK",
        "outputId": "2268d902-45d5-475f-fc8f-40c6c64c3bd2"
      },
      "outputs": [],
      "source": [
        "############################################################\n",
        "#  Evaluacion\n",
        "############################################################\n",
        "#Descargamos los pesos entrenados de forma local\n",
        "%cd /content/Mask_RCNN-tensorflow2.0/\n",
        "!gdown https://drive.google.com/uc?id=19ttEo7EYka9aSUA-zop_lXoSrqpT1kBH\n",
        "class InferenceConfig(CleanSeaConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    USE_MINI_MASK = False\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", \n",
        "                          config=inference_config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "\n",
        "# Get path to saved weights\n",
        "# Either set a specific path or find last trained weights\n",
        "model_path = os.path.join(ROOT_DIR, \"mask_rcnn_debris_weights200DA.h5\")\n",
        "#model_path = model.find_last()\n",
        "\n",
        "# Load trained weights\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)\n",
        "\n",
        "# Test on a random image\n",
        "image_id = random.choice(dataset_test.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_test, inference_config, \n",
        "                           image_id)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "euzCipgeOHFJ",
        "outputId": "b1c89bc1-9b61-49fe-980f-c81d992785f5"
      },
      "outputs": [],
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_test.class_names, r['scores'], ax=get_ax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "eQvQryCIOKPH",
        "outputId": "762c96c8-147a-43fc-fa75-176737826000"
      },
      "outputs": [],
      "source": [
        "# Test on a random image\n",
        "image_id = random.choice(dataset_test.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_test, inference_config, \n",
        "                           image_id)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "AxBHcvQ7ONdd",
        "outputId": "85d661c5-4496-43af-858d-5f2c75116b81"
      },
      "outputs": [],
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_test.class_names, r['scores'], ax=get_ax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGW3otTzOQgS",
        "outputId": "43d14deb-d590-4d66-80bb-50cf5a49f39c"
      },
      "outputs": [],
      "source": [
        "# Compute VOC-Style mAP @ IoU=0.5\n",
        "image_ids = dataset_test.image_ids\n",
        "APs = []\n",
        "for image_id in image_ids:\n",
        "    # Load image and ground truth data\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset_test, inference_config,\n",
        "                               image_id)\n",
        "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
        "    # Run object detection\n",
        "    results = model.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "    # Compute AP\n",
        "    AP, precisions, recalls, overlaps =\\\n",
        "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "    APs.append(AP)\n",
        "    \n",
        "print(\"mAP: \", np.mean(APs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J0faiaBT8E_"
      },
      "source": [
        "#### **Evaluacion con Pesos entrenados y ligero aumentado de Datos(500 Epocas)** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "B6aImwSCUIGi",
        "outputId": "e06cb82a-9379-4194-bde3-4c6327dbc5fc"
      },
      "outputs": [],
      "source": [
        "############################################################\n",
        "#  Evaluacion\n",
        "############################################################\n",
        "#Descargamos los pesos entrenados de forma local\n",
        "%cd /content/Mask_RCNN-tensorflow2.0/\n",
        "!gdown https://drive.google.com/uc?id=1HAJaN3SI4O-QozSY8ugo5VeaIaYTyh-6\n",
        "class InferenceConfig(CleanSeaConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    USE_MINI_MASK = False\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", \n",
        "                          config=inference_config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "\n",
        "# Get path to saved weights\n",
        "# Either set a specific path or find last trained weights\n",
        "model_path = os.path.join(ROOT_DIR, \"mask_rcnn_debris_weights500DA.h5\")\n",
        "#model_path = model.find_last()\n",
        "\n",
        "# Load trained weights\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)\n",
        "\n",
        "# Test on a random image\n",
        "image_id = random.choice(dataset_test.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_test, inference_config, \n",
        "                           image_id)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "0H4aB5l2UN7N",
        "outputId": "ea5101bf-baf8-43d6-8f81-e87be5921c41"
      },
      "outputs": [],
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_test.class_names, r['scores'], ax=get_ax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "GVUSWVinUQGK",
        "outputId": "798a1564-f285-4be6-f190-b514c1766043"
      },
      "outputs": [],
      "source": [
        "# Test on a random image\n",
        "image_id = random.choice(dataset_test.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_test, inference_config, \n",
        "                           image_id)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "3XToSG26USoC",
        "outputId": "354f36c4-06c8-4ce2-de34-8d7c26b74960"
      },
      "outputs": [],
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_test.class_names, r['scores'], ax=get_ax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJKg4qrAUVHg",
        "outputId": "7d7e305d-4953-4de1-a3ad-32286c592d9a"
      },
      "outputs": [],
      "source": [
        "# Compute VOC-Style mAP @ IoU=0.5\n",
        "image_ids = dataset_test.image_ids\n",
        "APs = []\n",
        "for image_id in image_ids:\n",
        "    # Load image and ground truth data\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset_test, inference_config,\n",
        "                               image_id)\n",
        "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
        "    # Run object detection\n",
        "    results = model.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "    # Compute AP\n",
        "    AP, precisions, recalls, overlaps =\\\n",
        "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "    APs.append(AP)\n",
        "    \n",
        "print(\"mAP: \", np.mean(APs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL6JsW6h3ZU6"
      },
      "source": [
        "#### **Evaluacion con Pesos entrenados y aumentado de Datos Severo (200 Epocas)** \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "2ElRUHH33e_g",
        "outputId": "62d3883f-7282-42d3-c215-a1b537c08df9"
      },
      "outputs": [],
      "source": [
        "############################################################\n",
        "#  Evaluacion\n",
        "############################################################\n",
        "#Descargamos los pesos entrenados de forma local\n",
        "%cd /content/Mask_RCNN-tensorflow2.0/\n",
        "!gdown https://drive.google.com/uc?id=1CTyoTKnXGcncAHfkotLas_vc0IRqMfZ2\n",
        "\n",
        "class InferenceConfig(CleanSeaConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    USE_MINI_MASK = False\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", \n",
        "                          config=inference_config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "\n",
        "# Get path to saved weights\n",
        "# Either set a specific path or find last trained weights\n",
        "model_path = os.path.join(ROOT_DIR, \"mask_rcnn_debris_weights200DA+.h5\")\n",
        "#model_path = model.find_last()\n",
        "\n",
        "# Load trained weights\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)\n",
        "\n",
        "# Test on a random image\n",
        "image_id = random.choice(dataset_test.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_test, inference_config, \n",
        "                           image_id)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "r1hFaoqK5_D9",
        "outputId": "f47a5e30-5c8e-4143-9ab5-eb844f31722e"
      },
      "outputs": [],
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_test.class_names, r['scores'], ax=get_ax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "upATP4u56B1-",
        "outputId": "93dad6ab-6b3a-4450-a79a-9d9ca28ac8ec"
      },
      "outputs": [],
      "source": [
        "# Test on a random image\n",
        "image_id = random.choice(dataset_test.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_test, inference_config, \n",
        "                           image_id)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "A9NDBaMZ6FDb",
        "outputId": "b0051046-0748-4385-d946-80728ae131a8"
      },
      "outputs": [],
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_test.class_names, r['scores'], ax=get_ax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNqlWdIz6LxG",
        "outputId": "c86a7dc7-c812-43dd-9317-a4b2750ad210"
      },
      "outputs": [],
      "source": [
        "# Compute VOC-Style mAP @ IoU=0.5\n",
        "image_ids = dataset_test.image_ids\n",
        "APs = []\n",
        "for image_id in image_ids:\n",
        "    # Load image and ground truth data\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset_test, inference_config,\n",
        "                               image_id)\n",
        "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
        "    # Run object detection\n",
        "    results = model.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "    # Compute AP\n",
        "    AP, precisions, recalls, overlaps =\\\n",
        "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "    APs.append(AP)\n",
        "    \n",
        "print(\"mAP: \", np.mean(APs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyyLBeUuRRcM"
      },
      "source": [
        "#### **Evaluacion con Pesos entrenados y aumentado de Datos severo (500 Epocas)** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "IYwFhTqRRgFf",
        "outputId": "91ed98fe-b0b1-4b70-c21b-33dec1d40bb2"
      },
      "outputs": [],
      "source": [
        "############################################################\n",
        "#  Evaluacion\n",
        "############################################################\n",
        "#Descargamos los pesos entrenados de forma local\n",
        "%cd /content/Mask_RCNN-tensorflow2.0/\n",
        "!gdown https://drive.google.com/uc?id=1SD-_6dSivqL5eEuvNRmAIzBVUtYeglP0\n",
        "class InferenceConfig(CleanSeaConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    USE_MINI_MASK = False\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", \n",
        "                          config=inference_config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "\n",
        "# Get path to saved weights\n",
        "# Either set a specific path or find last trained weights\n",
        "model_path = os.path.join(ROOT_DIR, \"mask_rcnn_debris_weights428DA5Heads.h5\")\n",
        "#model_path = model.find_last()\n",
        "\n",
        "# Load trained weights\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)\n",
        "\n",
        "# Test on a random image\n",
        "image_id = random.choice(dataset_test.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_test, inference_config, \n",
        "                           image_id)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "XFFxJ87HRlrp",
        "outputId": "88c2551a-3610-4922-9781-eb0ec455d22a"
      },
      "outputs": [],
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_test.class_names, r['scores'], ax=get_ax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "PjxsCN03Ro3C",
        "outputId": "93f3ee41-1dda-4908-eec2-1fb78cc20e6d"
      },
      "outputs": [],
      "source": [
        "# Test on a random image\n",
        "image_id = random.choice(dataset_test.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_test, inference_config, \n",
        "                           image_id)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "NXXdl79uRsQB",
        "outputId": "f99b0025-7dd4-4532-f293-b9b580149758"
      },
      "outputs": [],
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_test.class_names, r['scores'], ax=get_ax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvonNDJ4R8RG",
        "outputId": "26f40a98-f9be-4a09-b87e-f6820ef6482f"
      },
      "outputs": [],
      "source": [
        "# Compute VOC-Style mAP @ IoU=0.5\n",
        "image_ids = dataset_test.image_ids\n",
        "APs = []\n",
        "for image_id in image_ids:\n",
        "    # Load image and ground truth data\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset_test, inference_config,\n",
        "                               image_id)\n",
        "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
        "    # Run object detection\n",
        "    results = model.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "    # Compute AP\n",
        "    AP, precisions, recalls, overlaps =\\\n",
        "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "    APs.append(AP)\n",
        "    \n",
        "print(\"mAP: \", np.mean(APs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJkn7wuP0o87"
      },
      "source": [
        "# Inspeccin del modelo con mejores resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdpCEPQ-EvdG"
      },
      "source": [
        "## **Evaluacion con Pesos entrenados y aumentado de Datos severo (1000 Epocas)** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Boy32mzHEu37",
        "outputId": "f30356d7-4d40-4aab-a808-353d4ddc33f2"
      },
      "outputs": [],
      "source": [
        "############################################################\n",
        "#  Evaluacion\n",
        "############################################################\n",
        "#Descargamos los pesos entrenados de forma local\n",
        "%cd /content/Mask_RCNN-tensorflow2.0/\n",
        "!gdown https://drive.google.com/uc?id=1GmJ6zouasMsHw7t90IB_XHvz3wUuhrxZ\n",
        "class InferenceConfig(CleanSeaConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    USE_MINI_MASK = False\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", \n",
        "                          config=inference_config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "\n",
        "# Get path to saved weights\n",
        "# Either set a specific path or find last trained weights\n",
        "model_path = os.path.join(ROOT_DIR, \"mask_rcnn_debris_weights1000DA5Heads.h5\")\n",
        "#model_path = model.find_last()\n",
        "\n",
        "# Load trained weights\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHqmRY0D2j_p"
      },
      "source": [
        "### Deteccin Deseada vs Obtenida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "tsjYIeNDJfTG",
        "outputId": "b218c250-fe19-4094-d168-86a361050634"
      },
      "outputs": [],
      "source": [
        "# Test on a random image\n",
        "image_id = random.choice(dataset_test.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_test, inference_config, \n",
        "                           image_id)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_test.class_names, figsize=(8, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "mKp7_-tQE8Ih",
        "outputId": "e95d037d-f458-4443-8f55-1b9057981cc0"
      },
      "outputs": [],
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_test.class_names, r['scores'], ax=get_ax())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjG7gYpw2w6C"
      },
      "source": [
        "### Recuperacin de precisin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "iwrk4ba6ygt1",
        "outputId": "7cfa3076-e6a4-4dc8-95f0-64882f3d599a"
      },
      "outputs": [],
      "source": [
        "# Draw precision-recall curve\n",
        "AP, precisions, recalls, overlaps = utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "                                          r['rois'], r['class_ids'], r['scores'], r['masks'])\n",
        "visualize.plot_precision_recall(AP, precisions, recalls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrE8pI6g24U0"
      },
      "source": [
        "### Matriz de Confusin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "0bbLeO3zyqmr",
        "outputId": "385d4cfe-bfa6-4ba2-fbdc-3f90f2ce78e6"
      },
      "outputs": [],
      "source": [
        "# Grid of ground truth objects and their predictions\n",
        "visualize.plot_overlaps(gt_class_id, r['class_ids'], r['scores'],\n",
        "                        overlaps, dataset_test.class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b80mgn7j2-aQ"
      },
      "source": [
        "### Precisin del Modelo entrenado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PL51eo5y1Au",
        "outputId": "f1dc5c7d-1ade-43ec-d575-37f06d371606"
      },
      "outputs": [],
      "source": [
        "# Compute VOC-Style mAP @ IoU=0.5\n",
        "image_ids = dataset_test.image_ids\n",
        "APs = []\n",
        "for image_id in image_ids:\n",
        "    # Load image and ground truth data\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset_test, inference_config,\n",
        "                               image_id)\n",
        "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
        "    # Run object detection\n",
        "    results = model.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "    # Compute AP\n",
        "    AP, precisions, recalls, overlaps =\\\n",
        "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "    APs.append(AP)\n",
        "    \n",
        "print(\"mAP: \", np.mean(APs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCwVyiBl3KWI"
      },
      "source": [
        "## **Prediccin paso a paso**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXV0aD3q3abe"
      },
      "source": [
        "### Fase 1: RPN (Red de propuesta de regiones)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5Fr4iQ-3pX-"
      },
      "source": [
        "**OBJETIVOS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUELffKVzalt",
        "outputId": "d3ce5981-2098-45a8-df19-b7bcd9e36a6b"
      },
      "outputs": [],
      "source": [
        "# Generate RPN trainig targets\n",
        "# target_rpn_match is 1 for positive anchors, -1 for negative anchors\n",
        "# and 0 for neutral anchors.\n",
        "image_id = random.choice(dataset_test.image_ids)\n",
        "# Load image and ground truth data\n",
        "image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_test, inference_config,\n",
        "                            image_id)\n",
        "    \n",
        "target_rpn_match, target_rpn_bbox = modellib.build_rpn_targets(\n",
        "    image.shape, model.anchors, gt_class_id, gt_bbox, model.config)\n",
        "log(\"target_rpn_match\", target_rpn_match)\n",
        "log(\"target_rpn_bbox\", target_rpn_bbox)\n",
        "\n",
        "positive_anchor_ix = np.where(target_rpn_match[:] == 1)[0]\n",
        "negative_anchor_ix = np.where(target_rpn_match[:] == -1)[0]\n",
        "neutral_anchor_ix = np.where(target_rpn_match[:] == 0)[0]\n",
        "positive_anchors = model.anchors[positive_anchor_ix]\n",
        "negative_anchors = model.anchors[negative_anchor_ix]\n",
        "neutral_anchors = model.anchors[neutral_anchor_ix]\n",
        "log(\"positive_anchors\", positive_anchors)\n",
        "log(\"negative_anchors\", negative_anchors)\n",
        "log(\"neutral anchors\", neutral_anchors)\n",
        "\n",
        "# Apply refinement deltas to positive anchors\n",
        "refined_anchors = utils.apply_box_deltas(\n",
        "    positive_anchors,\n",
        "    target_rpn_bbox[:positive_anchors.shape[0]] * model.config.RPN_BBOX_STD_DEV)\n",
        "log(\"refined_anchors\", refined_anchors, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "rrh60Ftnzywn",
        "outputId": "12771515-d2a7-4f53-d331-ba319c800fcf"
      },
      "outputs": [],
      "source": [
        "# Display positive anchors before refinement (dotted) and\n",
        "# after refinement (solid).\n",
        "visualize.draw_boxes(image, boxes=positive_anchors, refined_boxes=refined_anchors, ax=get_ax())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDs6UHEE3wYT"
      },
      "source": [
        "**PREDICCIONES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuC5d8Coz6E-",
        "outputId": "d0e7605a-ec6a-4bf0-e0a6-6895da0b4a6b"
      },
      "outputs": [],
      "source": [
        "# Run RPN sub-graph\n",
        "pillar = model.keras_model.get_layer(\"ROI\").output  # node to start searching from\n",
        "\n",
        "# TF 1.4 and 1.9 introduce new versions of NMS. Search for all names to support TF 1.3~1.10\n",
        "nms_node = model.ancestor(pillar, \"ROI/rpn_non_max_suppression:0\")\n",
        "if nms_node is None:\n",
        "    nms_node = model.ancestor(pillar, \"ROI/rpn_non_max_suppression/NonMaxSuppressionV2:0\")\n",
        "if nms_node is None: #TF 1.9-1.10\n",
        "    nms_node = model.ancestor(pillar, \"ROI/rpn_non_max_suppression/NonMaxSuppressionV3:0\")\n",
        "\n",
        "rpn = model.run_graph([image], [\n",
        "    (\"rpn_class\", model.keras_model.get_layer(\"rpn_class\").output),\n",
        "    (\"pre_nms_anchors\", model.ancestor(pillar, \"ROI/pre_nms_anchors:0\")),\n",
        "    (\"refined_anchors\", model.ancestor(pillar, \"ROI/refined_anchors:0\")),\n",
        "    (\"refined_anchors_clipped\", model.ancestor(pillar, \"ROI/refined_anchors_clipped:0\")),\n",
        "    (\"post_nms_anchor_ix\", nms_node),\n",
        "    (\"proposals\", model.keras_model.get_layer(\"ROI\").output),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "uSuVcS3kz93s",
        "outputId": "c5076268-2944-4477-cf5c-99a988ff1bf5"
      },
      "outputs": [],
      "source": [
        "# Show top anchors by score (before refinement)\n",
        "limit = 100\n",
        "sorted_anchor_ids = np.argsort(rpn['rpn_class'][:,:,1].flatten())[::-1]\n",
        "visualize.draw_boxes(image, boxes=model.anchors[sorted_anchor_ids[:limit]], ax=get_ax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "RRn8JM9I0Aop",
        "outputId": "4cf2f064-2bd1-42d7-f297-cbea7623911e"
      },
      "outputs": [],
      "source": [
        "# Show top anchors with refinement. Then with clipping to image boundaries\n",
        "limit = 50\n",
        "ax = get_ax(1, 2)\n",
        "pre_nms_anchors = utils.denorm_boxes(rpn[\"pre_nms_anchors\"][0], image.shape[:2])\n",
        "refined_anchors = utils.denorm_boxes(rpn[\"refined_anchors\"][0], image.shape[:2])\n",
        "refined_anchors_clipped = utils.denorm_boxes(rpn[\"refined_anchors_clipped\"][0], image.shape[:2])\n",
        "visualize.draw_boxes(image, boxes=pre_nms_anchors[:limit],\n",
        "                     refined_boxes=refined_anchors[:limit], ax=ax[0])\n",
        "visualize.draw_boxes(image, refined_boxes=refined_anchors_clipped[:limit], ax=ax[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "fQ6pydK-0UYK",
        "outputId": "7abeee4e-017f-4674-89b8-c3bf39213814"
      },
      "outputs": [],
      "source": [
        "# Show final proposals\n",
        "# These are the same as the previous step (refined anchors \n",
        "# after NMS) but with coordinates normalized to [0, 1] range.\n",
        "limit = 50\n",
        "# Convert back to image coordinates for display\n",
        "h, w = config.IMAGE_SHAPE[:2]\n",
        "proposals = rpn['proposals'][0, :limit] * np.array([h, w, h, w])\n",
        "visualize.draw_boxes(image, refined_boxes=proposals, ax=get_ax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws_OjVZF0X65",
        "outputId": "2c71b23d-613b-43ee-90b4-4f51d82d5eaf"
      },
      "outputs": [],
      "source": [
        "# Measure the RPN recall (percent of objects covered by anchors)\n",
        "# Here we measure recall for 3 different methods:\n",
        "# - All anchors\n",
        "# - All refined anchors\n",
        "# - Refined anchors after NMS\n",
        "iou_threshold = 0.7\n",
        "\n",
        "recall, positive_anchor_ids = utils.compute_recall(model.anchors, gt_bbox, iou_threshold)\n",
        "print(\"All Anchors ({:5})       Recall: {:.3f}  Positive anchors: {}\".format(\n",
        "    model.anchors.shape[0], recall, len(positive_anchor_ids)))\n",
        "\n",
        "recall, positive_anchor_ids = utils.compute_recall(rpn['refined_anchors'][0], gt_bbox, iou_threshold)\n",
        "print(\"Refined Anchors ({:5})   Recall: {:.3f}  Positive anchors: {}\".format(\n",
        "    rpn['refined_anchors'].shape[1], recall, len(positive_anchor_ids)))\n",
        "\n",
        "recall, positive_anchor_ids = utils.compute_recall(proposals, gt_bbox, iou_threshold)\n",
        "print(\"Post NMS Anchors ({:5})  Recall: {:.3f}  Positive anchors: {}\".format(\n",
        "    proposals.shape[0], recall, len(positive_anchor_ids)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zluclr4V4AW5"
      },
      "source": [
        "### Fase 2: Propuesta de Clasificacin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_a0siAx0cp6",
        "outputId": "353f02d3-d9c5-42ad-f2c5-ac89f9f5ed69"
      },
      "outputs": [],
      "source": [
        "# Get input and output to classifier and mask heads.\n",
        "mrcnn = model.run_graph([image], [\n",
        "    (\"proposals\", model.keras_model.get_layer(\"ROI\").output),\n",
        "    (\"probs\", model.keras_model.get_layer(\"mrcnn_class\").output),\n",
        "    (\"deltas\", model.keras_model.get_layer(\"mrcnn_bbox\").output),\n",
        "    (\"masks\", model.keras_model.get_layer(\"mrcnn_mask\").output),\n",
        "    (\"detections\", model.keras_model.get_layer(\"mrcnn_detection\").output),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "QZJGKiF90hkf",
        "outputId": "73406b63-8775-4a77-a1e9-d9953cf2d6a9"
      },
      "outputs": [],
      "source": [
        "# Get detection class IDs. Trim zero padding.\n",
        "det_class_ids = mrcnn['detections'][0, :, 4].astype(np.int32)\n",
        "det_count = np.where(det_class_ids == 0)[0][0]\n",
        "det_class_ids = det_class_ids[:det_count]\n",
        "detections = mrcnn['detections'][0, :det_count]\n",
        "\n",
        "print(\"{} detections: {}\".format(\n",
        "    det_count, np.array(dataset_test.class_names)[det_class_ids]))\n",
        "\n",
        "captions = [\"{} {:.3f}\".format(dataset_test.class_names[int(c)], s) if c > 0 else \"\"\n",
        "            for c, s in zip(detections[:, 4], detections[:, 5])]\n",
        "visualize.draw_boxes(\n",
        "    image, \n",
        "    refined_boxes=utils.denorm_boxes(detections[:, :4], image.shape[:2]),\n",
        "    visibilities=[2] * len(detections),\n",
        "    captions=captions, title=\"Detections\",\n",
        "    ax=get_ax())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-k9jbqG4nSs"
      },
      "source": [
        "**DETECCIN PASO A PASO**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXHdSMcz4Z6J",
        "outputId": "f88ee675-bbb8-4743-bb91-13601f4748ca"
      },
      "outputs": [],
      "source": [
        "# Proposals are in normalized coordinates. Scale them\n",
        "# to image coordinates.\n",
        "h, w = config.IMAGE_SHAPE[:2]\n",
        "proposals = np.around(mrcnn[\"proposals\"][0] * np.array([h, w, h, w])).astype(np.int32)\n",
        "\n",
        "# Class ID, score, and mask per proposal\n",
        "roi_class_ids = np.argmax(mrcnn[\"probs\"][0], axis=1)\n",
        "roi_scores = mrcnn[\"probs\"][0, np.arange(roi_class_ids.shape[0]), roi_class_ids]\n",
        "roi_class_names = np.array(dataset_test.class_names)[roi_class_ids]\n",
        "roi_positive_ixs = np.where(roi_class_ids > 0)[0]\n",
        "\n",
        "# How many ROIs vs empty rows?\n",
        "print(\"{} Valid proposals out of {}\".format(np.sum(np.any(proposals, axis=1)), proposals.shape[0]))\n",
        "print(\"{} Positive ROIs\".format(len(roi_positive_ixs)))\n",
        "\n",
        "# Class counts\n",
        "print(list(zip(*np.unique(roi_class_names, return_counts=True))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "fiMrGc5S4fIH",
        "outputId": "2fa90234-8ec9-4a33-899e-e9260f9ea599"
      },
      "outputs": [],
      "source": [
        "# Display a random sample of proposals.\n",
        "# Proposals classified as background are dotted, and\n",
        "# the rest show their class and confidence score.\n",
        "limit = 200\n",
        "ixs = np.random.randint(0, proposals.shape[0], limit)\n",
        "captions = [\"{} {:.3f}\".format(dataset_test.class_names[c], s) if c > 0 else \"\"\n",
        "            for c, s in zip(roi_class_ids[ixs], roi_scores[ixs])]\n",
        "visualize.draw_boxes(image, boxes=proposals[ixs],\n",
        "                     visibilities=np.where(roi_class_ids[ixs] > 0, 2, 1),\n",
        "                     captions=captions, title=\"ROIs Before Refinement\",\n",
        "                     ax=get_ax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "SwzZSe3s4s4C",
        "outputId": "8d9d24ae-1160-4232-9ba4-726fa8911d0b"
      },
      "outputs": [],
      "source": [
        "# Class-specific bounding box shifts.\n",
        "roi_bbox_specific = mrcnn[\"deltas\"][0, np.arange(proposals.shape[0]), roi_class_ids]\n",
        "log(\"roi_bbox_specific\", roi_bbox_specific)\n",
        "\n",
        "# Apply bounding box transformations\n",
        "# Shape: [N, (y1, x1, y2, x2)]\n",
        "refined_proposals = utils.apply_box_deltas(\n",
        "    proposals, roi_bbox_specific * config.BBOX_STD_DEV).astype(np.int32)\n",
        "log(\"refined_proposals\", refined_proposals)\n",
        "\n",
        "# Show positive proposals\n",
        "# ids = np.arange(roi_boxes.shape[0])  # Display all\n",
        "limit = 5\n",
        "ids = np.random.randint(0, len(roi_positive_ixs), limit)  # Display random sample\n",
        "captions = [\"{} {:.3f}\".format(dataset_test.class_names[c], s) if c > 0 else \"\"\n",
        "            for c, s in zip(roi_class_ids[roi_positive_ixs][ids], roi_scores[roi_positive_ixs][ids])]\n",
        "visualize.draw_boxes(image, boxes=proposals[roi_positive_ixs][ids],\n",
        "                     refined_boxes=refined_proposals[roi_positive_ixs][ids],\n",
        "                     visibilities=np.where(roi_class_ids[roi_positive_ixs][ids] > 0, 1, 0),\n",
        "                     captions=captions, title=\"ROIs After Refinement\",\n",
        "                     ax=get_ax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXjGwbHZ42gL",
        "outputId": "cb07a714-a69b-476c-928b-4e12e426e7c1"
      },
      "outputs": [],
      "source": [
        "# Remove boxes classified as background\n",
        "keep = np.where(roi_class_ids > 0)[0]\n",
        "print(\"Keep {} detections:\\n{}\".format(keep.shape[0], keep))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o__yRLr145YQ",
        "outputId": "a1dca6e5-966a-4382-a8cf-338e4c574d3d"
      },
      "outputs": [],
      "source": [
        "# Remove low confidence detections\n",
        "keep = np.intersect1d(keep, np.where(roi_scores >= config.DETECTION_MIN_CONFIDENCE)[0])\n",
        "print(\"Remove boxes below {} confidence. Keep {}:\\n{}\".format(\n",
        "    config.DETECTION_MIN_CONFIDENCE, keep.shape[0], keep))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5urLgUjO48ON",
        "outputId": "36b66c54-80fb-426b-eb0e-fde212652cc8"
      },
      "outputs": [],
      "source": [
        "# Apply per-class non-max suppression\n",
        "pre_nms_boxes = refined_proposals[keep]\n",
        "pre_nms_scores = roi_scores[keep]\n",
        "pre_nms_class_ids = roi_class_ids[keep]\n",
        "\n",
        "nms_keep = []\n",
        "for class_id in np.unique(pre_nms_class_ids):\n",
        "    # Pick detections of this class\n",
        "    ixs = np.where(pre_nms_class_ids == class_id)[0]\n",
        "    # Apply NMS\n",
        "    class_keep = utils.non_max_suppression(pre_nms_boxes[ixs], \n",
        "                                            pre_nms_scores[ixs],\n",
        "                                            config.DETECTION_NMS_THRESHOLD)\n",
        "    # Map indicies\n",
        "    class_keep = keep[ixs[class_keep]]\n",
        "    nms_keep = np.union1d(nms_keep, class_keep)\n",
        "    print(\"{:22}: {} -> {}\".format(dataset_test.class_names[class_id][:20], \n",
        "                                   keep[ixs], class_keep))\n",
        "\n",
        "keep = np.intersect1d(keep, nms_keep).astype(np.int32)\n",
        "print(\"\\nKept after per-class NMS: {}\\n{}\".format(keep.shape[0], keep))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "zzwxsxgN5Bdh",
        "outputId": "a752f51b-1b4c-4c54-8353-4c2244ee3b85"
      },
      "outputs": [],
      "source": [
        "# Show final detections\n",
        "ixs = np.arange(len(keep))  # Display all\n",
        "# ixs = np.random.randint(0, len(keep), 10)  # Display random sample\n",
        "captions = [\"{} {:.3f}\".format(dataset_test.class_names[c], s) if c > 0 else \"\"\n",
        "            for c, s in zip(roi_class_ids[keep][ixs], roi_scores[keep][ixs])]\n",
        "visualize.draw_boxes(\n",
        "    image, boxes=proposals[keep][ixs],\n",
        "    refined_boxes=refined_proposals[keep][ixs],\n",
        "    visibilities=np.where(roi_class_ids[keep][ixs] > 0, 1, 0),\n",
        "    captions=captions, title=\"Detections after NMS\",\n",
        "    ax=get_ax())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiB2AdCp5GjZ"
      },
      "source": [
        "### Fase 3: Generacin de Mscaras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "a8nOjkpi6D-V",
        "outputId": "641979c4-5319-478c-b670-648818b43589"
      },
      "outputs": [],
      "source": [
        "def display_images(images, titles=None, cols=4, cmap=None, norm=None,\n",
        "                   interpolation=None):\n",
        "    \"\"\"Display the given set of images, optionally with titles.\n",
        "    images: list or array of image tensors in HWC format.\n",
        "    titles: optional. A list of titles to display with each image.\n",
        "    cols: number of images per row\n",
        "    cmap: Optional. Color map to use. For example, \"Blues\".\n",
        "    norm: Optional. A Normalize instance to map values to colors.\n",
        "    interpolation: Optional. Image interpolation to use for display.\n",
        "    \"\"\"\n",
        "    titles = titles if titles is not None else [\"\"] * len(images)\n",
        "    rows = len(images) // cols + 1\n",
        "    plt.figure(figsize=(14, 14 * rows // cols))\n",
        "    i = 1\n",
        "    for image, title in zip(images, titles):\n",
        "        plt.subplot(rows, cols, i)\n",
        "        plt.title(title, fontsize=9)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(image.astype(np.uint8), cmap=cmap,\n",
        "                   norm=norm, interpolation=interpolation)\n",
        "        i += 1\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "display_images(np.transpose(gt_mask, [2, 0, 1]), cmap=\"Blues\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY8C5qPC6Jxr",
        "outputId": "62bba6db-798d-400a-e349-a49603931b3f"
      },
      "outputs": [],
      "source": [
        "# Get predictions of mask head\n",
        "mrcnn = model.run_graph([image], [\n",
        "    (\"detections\", model.keras_model.get_layer(\"mrcnn_detection\").output),\n",
        "    (\"masks\", model.keras_model.get_layer(\"mrcnn_mask\").output),\n",
        "])\n",
        "\n",
        "# Get detection class IDs. Trim zero padding.\n",
        "det_class_ids = mrcnn['detections'][0, :, 4].astype(np.int32)\n",
        "det_count = np.where(det_class_ids == 0)[0][0]\n",
        "det_class_ids = det_class_ids[:det_count]\n",
        "\n",
        "print(\"{} detections: {}\".format(\n",
        "    det_count, np.array(dataset_test.class_names)[det_class_ids]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VK000buZ6OuL",
        "outputId": "b2e9e40a-9643-4361-d300-59ba30965513"
      },
      "outputs": [],
      "source": [
        "# Masks\n",
        "det_boxes = utils.denorm_boxes(mrcnn[\"detections\"][0, :, :4], image.shape[:2])\n",
        "det_mask_specific = np.array([mrcnn[\"masks\"][0, i, :, :, c] \n",
        "                              for i, c in enumerate(det_class_ids)])\n",
        "det_masks = np.array([utils.unmold_mask(m, det_boxes[i], image.shape)\n",
        "                      for i, m in enumerate(det_mask_specific)])\n",
        "log(\"det_mask_specific\", det_mask_specific)\n",
        "log(\"det_masks\", det_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "DRLeB5uW6Q40",
        "outputId": "b3b5b050-5fb7-4eaa-a1de-51b99e0b8087"
      },
      "outputs": [],
      "source": [
        "display_images(det_mask_specific[:4] * 255, cmap=\"Blues\", interpolation=\"none\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZjRwXj_6Vy3"
      },
      "source": [
        "### Visualizacin de las Activaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkWgPMi_5OXB",
        "outputId": "6a8392b7-0502-4997-b096-9230533a4ccc"
      },
      "outputs": [],
      "source": [
        "# Get activations of a few sample layers\n",
        "activations = model.run_graph([image], [\n",
        "    (\"input_image\",        tf.identity(model.keras_model.get_layer(\"input_image\").output)),\n",
        "    (\"res4w_out\",          model.keras_model.get_layer(\"res4w_out\").output),  # for resnet100\n",
        "    (\"rpn_bbox\",           model.keras_model.get_layer(\"rpn_bbox\").output),\n",
        "    (\"roi\",                model.keras_model.get_layer(\"ROI\").output),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "BJCV8yry5kE8",
        "outputId": "a349c49d-b43f-4778-e3fc-66bdbbcafe8b"
      },
      "outputs": [],
      "source": [
        "# Input image (normalized)\n",
        "_ = plt.imshow(modellib.unmold_image(activations[\"input_image\"][0],config))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "h3shPqpR5nZu",
        "outputId": "2fe38bbd-709a-44fb-ae47-ba8df704c47e"
      },
      "outputs": [],
      "source": [
        "# Backbone feature map\n",
        "def display_images(images, titles=None, cols=4, cmap=None, norm=None,\n",
        "                   interpolation=None):\n",
        "    \"\"\"Display the given set of images, optionally with titles.\n",
        "    images: list or array of image tensors in HWC format.\n",
        "    titles: optional. A list of titles to display with each image.\n",
        "    cols: number of images per row\n",
        "    cmap: Optional. Color map to use. For example, \"Blues\".\n",
        "    norm: Optional. A Normalize instance to map values to colors.\n",
        "    interpolation: Optional. Image interpolation to use for display.\n",
        "    \"\"\"\n",
        "    titles = titles if titles is not None else [\"\"] * len(images)\n",
        "    rows = len(images) // cols + 1\n",
        "    plt.figure(figsize=(14, 14 * rows // cols))\n",
        "    i = 1\n",
        "    for image, title in zip(images, titles):\n",
        "        plt.subplot(rows, cols, i)\n",
        "        plt.title(title, fontsize=9)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(image.astype(np.uint8), cmap=cmap,\n",
        "                   norm=norm, interpolation=interpolation)\n",
        "        i += 1\n",
        "    plt.show()\n",
        "display_images(np.transpose(activations[\"res4w_out\"][0,:,:,:4], [2, 0, 1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "WJ3WJw7c5rqv",
        "outputId": "e7da35aa-e835-4cb7-eda0-42f2adce8525"
      },
      "outputs": [],
      "source": [
        "# Histograms of RPN bounding box deltas\n",
        "plt.figure(figsize=(12, 3))\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.title(\"dy\")\n",
        "_ = plt.hist(activations[\"rpn_bbox\"][0,:,0], 50)\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.title(\"dx\")\n",
        "_ = plt.hist(activations[\"rpn_bbox\"][0,:,1], 50)\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.title(\"dw\")\n",
        "_ = plt.hist(activations[\"rpn_bbox\"][0,:,2], 50)\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.title(\"dh\")\n",
        "_ = plt.hist(activations[\"rpn_bbox\"][0,:,3], 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "kScZz9Y-5uvp",
        "outputId": "34877eac-61a9-4fc0-e47f-98be0d85e909"
      },
      "outputs": [],
      "source": [
        "# Distribution of y, x coordinates of generated proposals\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"y1, x1\")\n",
        "plt.scatter(activations[\"roi\"][0,:,0], activations[\"roi\"][0,:,1])\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"y2, x2\")\n",
        "plt.scatter(activations[\"roi\"][0,:,2], activations[\"roi\"][0,:,3])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "o-Sn7zuMN872",
        "hJHD0oDE5mul",
        "OyYIxexetudA",
        "sPizH7qO6TYR",
        "o_sRiMzCBX1x",
        "Ch0rdplzBsP9",
        "-AagKz7yCRRc",
        "Jp9YoapgQ14Q",
        "2QkzvxgHC2S2",
        "6Aho3nhCMowl",
        "DbnalzXScdy0",
        "-6aRvrzsBtWM",
        "BZd_I2HgzEUX"
      ],
      "name": "Proyecto CleanSea.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.7.11 ('cleansea')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "cea2676ec9d0180d7a0a4cfbef118e05e2dcfabc73690db4cf2084bcf6d0071c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
